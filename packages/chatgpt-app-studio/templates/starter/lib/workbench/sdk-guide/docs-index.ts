// Auto-generated by scripts/build-sdk-docs-index.ts
// Do not edit manually

export interface DocChunk {
  id: string;
  source: string;
  heading: string;
  content: string;
  keywords: string[];
}

export const SDK_DOCS_INDEX: DocChunk[] = [
  {
    id: "api-and-sdk-reference-0",
    source: "API and SDK reference",
    heading: "`window.openai` component bridge",
    content: "See [build a ChatGPT UI](/apps-sdk/build/chatgpt-ui).",
    keywords: ["build", "chatgpt", "apps", "sdk"],
  },
  {
    id: "api-and-sdk-reference-1",
    source: "API and SDK reference",
    heading: "File APIs",
    content:
      "| API                                            | Purpose                                             | Notes                                                                  |\n| ---------------------------------------------- | --------------------------------------------------- | ---------------------------------------------------------------------- |\n| `window.openai.uploadFile(file)`               | Upload a user-selected file and receive a `fileId`. | Supports `image/png`, `image/jpeg`, `image/webp`.                      |\n| `window.openai.getFileDownloadUrl({ fileId })` | Request a temporary download URL for a file.        | Only works for files uploaded by the widget or passed via file params. |\n\nWhen persisting widget state, use the structured shape (`modelContent`, `privateContent`, `imageIds`) if you want the model to see image IDs during follow-up turns.",
    keywords: [
      "file",
      "image",
      "window",
      "openai",
      "fileid",
      "widget",
      "api",
      "purpose",
      "notes",
      "uploadfile",
      "upload",
      "user",
      "selected",
      "receive",
      "supports",
    ],
  },
  {
    id: "api-and-sdk-reference-2",
    source: "API and SDK reference",
    heading: "Tool descriptor parameters",
    content:
      'Need more background on these fields? Check the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced).\n\nBy default, a tool description should include the fields listed [here](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#tool).\n\n### `_meta` fields on tool descriptor\n\nWe have also require the following `_meta` fields on the tool descriptor:\n\n| Key                                       |    Placement    | Type         | Limits                          | Purpose                                                                                         |\n| ----------------------------------------- | :-------------: | ------------ | ------------------------------- | ----------------------------------------------------------------------------------------------- |\n| `_meta["securitySchemes"]`                | Tool descriptor | array        | —                               | Back-compat mirror for clients that only read `_meta`.                                          |\n| `_meta["openai/outputTemplate"]`          | Tool descriptor | string (URI) | —                               | Resource URI for component HTML template (`text/html+skybridge`).                               |\n| `_meta["openai/widgetAccessible"]`        | Tool descriptor | boolean      | default `false`                 | Allow component→tool calls through the client bridge.                                           |\n| `_meta["openai/visibility"]`              | Tool descriptor | string       | `public` (default) or `private` | Hide a tool from the model while keeping it callable from the widget.                           |\n| `_meta["openai/toolInvocation/invoking"]` | Tool descriptor | string       | ≤ 64 chars                      | Short status text while the tool runs.                                                          |\n| `_meta["openai/toolInvocation/invoked"]`  | Tool descriptor | string       | ≤ 64 chars                      | Short status text after the tool completes.                                                     |\n| `_meta["openai/fileParams"].            ` | Tool descriptor | string[]     | —                               | List of top-level input fields that represent files (object shape `{ download_url, file_id }`). |\n\nExample:\n\n```ts\nserver.registerTool(\n  "search",\n  {\n    title: "Public Search",\n    description: "Search public documents.",\n    inputSchema: {\n      type: "object",\n      properties: { q: { type: "string" } },\n      required: ["q"],\n    },\n    securitySchemes: [\n      { type: "noauth" },\n      { type: "oauth2", scopes: ["search.read"] },\n    ],\n    _meta: {\n      securitySchemes: [\n        { type: "noauth" },\n        { type: "oauth2", scopes: ["search.read"] },\n      ],\n      "openai/outputTemplate": "ui://widget/story.html",\n      "openai/toolInvocation/invoking": "Searching…",\n      "openai/toolInvocation/invoked": "Results ready",\n    },\n  },\n  async ({ q }) => performSearch(q),\n);\n```\n\n### Annotations\n\nTo label a tool as "read-only", please use the following [annotation](https://modelcontextprotocol.io/specification/2025-06-18/server/resources#annotations) on the tool descriptor:\n\n| Key               | Type    | Required | Notes                                                                                                                                                           |\n| ----------------- | ------- | :------: | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `readOnlyHint`    | boolean | Required | Signal that the tool is read-only. ChatGPT can skip “Are you sure?” prompts when this is `true`.                                                                |\n| `destructiveHint` | boolean | Required | Declare that the tool may delete or overwrite user data so ChatGPT knows to elicit explicit approval first.                                                     |\n| `openWorldHint`   | boolean | Required | Declare that the tool publishes content or reaches outside the current user’s account, prompting the client to summarize the impact before asking for approval. |\n| `idempotentHint`  | boolean | Optional | Declare that calling the tool repeatedly with the same arguments will have no additional effect on its environment.                                             |\n\nThese hints only influence how ChatGPT frames the tool call to the user; servers must still enforce their own authorization logic.\n\nExample:\n\n```ts\nserver.registerTool(\n  "list_saved_recipes",\n  {\n    title: "List saved recipes",\n    description: "Returns the user’s saved recipes without modifying them.",\n    inputSchema: {\n      type: "object",\n      properties: {},\n      additionalProperties: false,\n    },\n    annotations: { readOnlyHint: true },\n  },\n  async () => fetchSavedRecipes(),\n);\n```\n\nNeed more background on these fields? Check the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced).',
    keywords: [
      "tool",
      "_meta",
      "descriptor",
      "type",
      "openai",
      "server",
      "fields",
      "string",
      "read",
      "boolean",
      "search",
      "required",
      "advanced",
      "mcp",
      "only",
    ],
  },
  {
    id: "api-and-sdk-reference-3",
    source: "API and SDK reference",
    heading: "Component resource `_meta` fields",
    content:
      'Additional detail on these resource settings lives in the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced).\n\nSet these keys on the resource template that serves your component (`registerResource`). They help ChatGPT describe and frame the rendered iframe without leaking metadata to other clients.\n\n| Key                                   |     Placement     | Type            | Purpose                                                                                                                                                                 |\n| ------------------------------------- | :---------------: | --------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `_meta["openai/widgetDescription"]`   | Resource contents | string          | Human-readable summary surfaced to the model when the component loads, reducing redundant assistant narration.                                                          |\n| `_meta["openai/widgetPrefersBorder"]` | Resource contents | boolean         | Hint that the component should render inside a bordered card when supported.                                                                                            |\n| `_meta["openai/widgetCSP"]`           | Resource contents | object          | Define CSP allowlists for the widget: `connect_domains` (network requests), `resource_domains` (images, fonts, scripts), and optional `frame_domains` (iframe sources). |\n| `_meta["openai/widgetDomain"]`        | Resource contents | string (origin) | Optional dedicated subdomain for hosted components (defaults to `https://web-sandbox.oaiusercontent.com`).                                                              |\n\nThe `openai/widgetCSP` object supports:\n\n- `connect_domains`: `string[]` – domains the widget may contact via fetch/XHR.\n- `resource_domains`: `string[]` – domains for static assets (images, fonts, scripts, styles).\n- `frame_domains?`: `string[]` – optional list of origins allowed for iframe embeds. By default, widgets cannot render subframes; adding `frame_domains` opts in to iframe usage and triggers stricter app review.',
    keywords: [
      "resource",
      "openai",
      "string",
      "iframe",
      "_meta",
      "contents",
      "component",
      "optional",
      "frame_domains",
      "advanced",
      "mcp",
      "server",
      "render",
      "widgetcsp",
      "object",
    ],
  },
  {
    id: "api-and-sdk-reference-4",
    source: "API and SDK reference",
    heading: "Tool results",
    content:
      'The [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced) provides more guidance on shaping these response fields.\n\nTool results can contain the following [fields](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#tool-result). Notably:\n\n| Key                 | Type                  | Required | Notes                                                                                           |\n| ------------------- | --------------------- | -------- | ----------------------------------------------------------------------------------------------- |\n| `structuredContent` | object                | Optional | Surfaced to the model and the component. Must match the declared `outputSchema`, when provided. |\n| `content`           | string or `Content[]` | Optional | Surfaced to the model and the component.                                                        |\n| `_meta`             | object                | Optional | Delivered only to the component. Hidden from the model.                                         |\n\nOnly `structuredContent` and `content` appear in the conversation transcript. `_meta` is forwarded to the component so you can hydrate UI without exposing the data to the model.\n\nHost-provided tool result metadata:\n\n| Key                               |            Placement            | Type   | Purpose                                                                                                                 |\n| --------------------------------- | :-----------------------------: | ------ | ----------------------------------------------------------------------------------------------------------------------- |\n| `_meta["openai/widgetSessionId"]` | Tool result `_meta` (from host) | string | Stable ID for the currently mounted widget instance; use it to correlate logs and tool calls until the widget unmounts. |\n\nExample:\n\n```ts\nserver.registerTool(\n  "get_zoo_animals",\n  {\n    title: "get_zoo_animals",\n    inputSchema: { count: z.number().int().min(1).max(20).optional() },\n    _meta: { "openai/outputTemplate": "ui://widget/widget.html" },\n  },\n  async ({ count = 10 }) => {\n    const animals = generateZooAnimals(count);\n\n    return {\n      structuredContent: { animals },\n      content: [{ type: "text", text: `Here are ${animals.length} animals.` }],\n      _meta: {\n        allAnimalsById: Object.fromEntries(\n          animals.map((animal) => [animal.id, animal]),\n        ),\n      },\n    };\n  },\n);\n```\n\n### Error tool result\n\nTo return an error on the tool result, use the following `_meta` key:\n\n| Key                             | Purpose      | Type               | Notes                                                    |\n| ------------------------------- | ------------ | ------------------ | -------------------------------------------------------- |\n| `_meta["mcp/www_authenticate"]` | Error result | string or string[] | RFC 7235 `WWW-Authenticate` challenges to trigger OAuth. |',
    keywords: [
      "_meta",
      "tool",
      "result",
      "animals",
      "server",
      "key",
      "type",
      "optional",
      "model",
      "component",
      "content",
      "string",
      "widget",
      "mcp",
      "structuredcontent",
    ],
  },
  {
    id: "api-and-sdk-reference-5",
    source: "API and SDK reference",
    heading: "`_meta` fields the client provides",
    content:
      'See the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced) for broader context on these client-supplied hints.\n\n| Key                            | When provided           | Type            | Purpose                                                                                     |\n| ------------------------------ | ----------------------- | --------------- | ------------------------------------------------------------------------------------------- |\n| `_meta["openai/locale"]`       | Initialize + tool calls | string (BCP 47) | Requested locale (older clients may send `_meta["webplus/i18n"]`).                          |\n| `_meta["openai/userAgent"]`    | Tool calls              | string          | User agent hint for analytics or formatting.                                                |\n| `_meta["openai/userLocation"]` | Tool calls              | object          | Coarse location hint (`city`, `region`, `country`, `timezone`, `longitude`, `latitude`).    |\n| `_meta["openai/subject"]`      | Tool calls              | string          | Anonymized user id sent to MCP servers for the purposes of rate limiting and identification |\n\nOperation-phase `_meta["openai/userAgent"]` and `_meta["openai/userLocation"]` are hints only; servers should never rely on them for authorization decisions and must tolerate their absence.\n\nExample:\n\n```ts\nserver.registerTool(\n  "recommend_cafe",\n  {\n    title: "Recommend a cafe",\n    inputSchema: { type: "object" },\n  },\n  async (_args, { _meta }) => {\n    const locale = _meta?.["openai/locale"] ?? "en";\n    const location = _meta?.["openai/userLocation"]?.city;\n\n    return {\n      content: [{ type: "text", text: formatIntro(locale, location) }],\n      structuredContent: await findNearbyCafes(location),\n    };\n  },\n);\n```',
    keywords: [
      "_meta",
      "openai",
      "locale",
      "tool",
      "calls",
      "location",
      "mcp",
      "server",
      "type",
      "string",
      "userlocation",
      "advanced",
      "hints",
      "useragent",
      "user",
    ],
  },
  {
    id: "authentication-0",
    source: "Authentication",
    heading: "Authenticate your users",
    content:
      "Many Apps SDK apps can operate in a read-only, anonymous mode, but anything that exposes customer-specific data or write actions should authenticate users.\n\nYou can integrate with your own authorization server when you need to connect to an existing backend or share data between users.",
    keywords: [
      "apps",
      "data",
      "users",
      "many",
      "sdk",
      "operate",
      "read",
      "only",
      "anonymous",
      "mode",
      "anything",
      "exposes",
      "customer",
      "specific",
      "write",
    ],
  },
  {
    id: "authentication-1",
    source: "Authentication",
    heading: "Custom auth with OAuth 2.1",
    content:
      'For an authenticated MCP server, you are expected to implement a OAuth 2.1 flow that conforms to the [MCP authorization spec](https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization).\n\n### Components\n\n- **Resource server** – your MCP server, which exposes tools and verifies access tokens on each request.\n- **Authorization server** – your identity provider (Auth0, Okta, Cognito, or a custom implementation) that issues tokens and publishes discovery metadata.\n- **Client** – ChatGPT acting on behalf of the user. It supports dynamic client registration and PKCE.\n\n### MCP authorization spec requirements\n\n- Host protected resource metadata on your MCP server\n- Publish OAuth metadata from your authorization server\n- Echo the `resource` parameter throughout the OAuth flow\n- Advertise PKCE support for ChatGPT\n\nHere is what the spec expects, in plain language.\n\n#### Host protected resource metadata on your MCP server\n\n- You need an HTTPS endpoint such as `GET https://your-mcp.example.com/.well-known/oauth-protected-resource` (or advertise the same URL in a `WWW-Authenticate` header on `401 Unauthorized` responses) so ChatGPT knows where to fetch your metadata.\n- That endpoint returns a JSON document describing the resource server and its available authorization servers:\n\n```json\n{\n  "resource": "https://your-mcp.example.com",\n  "authorization_servers": ["https://auth.yourcompany.com"],\n  "scopes_supported": ["files:read", "files:write"],\n  "resource_documentation": "https://yourcompany.com/docs/mcp"\n}\n```\n\n- Key fields you must populate:\n  - `resource`: the canonical HTTPS identifier for your MCP server. ChatGPT sends this exact value as the `resource` query parameter during OAuth.\n  - `authorization_servers`: one or more issuer base URLs that point to your identity provider. ChatGPT will try each to find OAuth metadata.\n  - `scopes_supported`: optional list that helps ChatGPT explain the permissions it is going to ask the user for.\n  - Optional extras from [RFC 9728](https://datatracker.ietf.org/doc/html/rfc9728) such as `resource_documentation`, `token_endpoint_auth_methods_supported`, or `introspection_endpoint` make it easier for clients and admins to understand your setup.\n\nWhen you block a request because it is unauthenticated, return a challenge like:\n\n```http\nHTTP/1.1 401 Unauthorized\nWWW-Authenticate: Bearer resource_metadata="https://your-mcp.example.com/.well-known/oauth-protected-resource",\n                         scope="files:read"\n```\n\nThat single header lets ChatGPT discover the metadata URL even if it has not seen it before.\n\n#### Publish OAuth metadata from your authorization server\n\n- Your identity provider must expose one of the well-known discovery documents so ChatGPT can read its configuration:\n  - OAuth 2.0 metadata at `https://auth.yourcompany.com/.well-known/oauth-authorization-server`\n  - OpenID Connect metadata at `https://auth.yourcompany.com/.well-known/openid-configuration`\n- Each document answers three big questions for ChatGPT: where to send the user, how to exchange codes, and how to register itself. A typical response looks like:\n\n```json\n{\n  "issuer": "https://auth.yourcompany.com",\n  "authorization_endpoint": "https://auth.yourcompany.com/oauth2/v1/authorize",\n  "token_endpoint": "https://auth.yourcompany.com/oauth2/v1/token",\n  "registration_endpoint": "https://auth.yourcompany.com/oauth2/v1/register",\n  "code_challenge_methods_supported": ["S256"],\n  "scopes_supported": ["files:read", "files:write"]\n}\n```\n\n- Fields that must be correct:\n  - `authorization_endpoint`, `token_endpoint`: the URLs ChatGPT needs to run the OAuth authorization-code + PKCE flow end to end.\n  - `registration_endpoint`: enables dynamic client registration (DCR) so ChatGPT can mint a dedicated `client_id` per connector.\n  - `code_challenge_methods_supported`: must include `S256`, otherwise ChatGPT will refuse to proceed because PKCE appears unsupported.\n  - Optional fields follow [RFC 8414](https://datatracker.ietf.org/doc/html/rfc8414) / [OpenID Discovery](https://openid.net/specs/openid-connect-discovery-1_0.html); include whatever helps your administrators configure policies.\n\n#### Redirect URL\n\nChatGPT completes the OAuth flow by redirecting to `https://chatgpt.com/connector_platform_oauth_redirect`. Add that production redirect URL to your authorization server\'s allowlist so the authorization code can be returned successfully.\n\n#### Echo the `resource` parameter throughout the OAuth flow\n\n- Expect ChatGPT to append `resource=https%3A%2F%2Fyour-mcp.example.com` to both the authorization and token requests. This ties the token back to the protected resource metadata shown above.\n- Configure your authorization server to copy that value into the access token (commonly the `aud` claim) so your MCP server can verify the token was minted for it and nobody else.\n- If a token arrives without the expected audience or scopes, reject it and rely on the `WWW-Authenticate` challenge to prompt ChatGPT to re-authorize with the correct parameters.\n\n#### Advertise PKCE support for ChatGPT\n\n- ChatGPT, acting as the MCP client, performs the authorization-code flow with PKCE using the `S256` code challenge so intercepted authorization codes cannot be replayed by an attacker. That protection is why the MCP authorization spec mandates PKCE.\n- Your authorization server metadata therefore needs to list `code_challenge_methods_supported` (or equivalent) including `S256`. If that field is missing, ChatGPT will refuse to complete the flow because it cannot confirm PKCE support.\n\n### OAuth flow\n\nProvided that you have implemented the MCP authorization spec delineated above, the OAuth flow will be as follows:\n\n1. ChatGPT queries your MCP server for protected resource metadata.\n\n![](/images/apps-sdk/protected_resource_metadata.png)\n\n2. ChatGPT registers itself via dynamic client registration with your authorization server using the `registration_endpoint` and obtains a `client_id`.\n\n![](/images/apps-sdk/client_registration.png)\n\n3. When the user first invokes a tool, the ChatGPT client launches the OAuth authorization code + PKCE flow. The user authenticates and consents to the requested scopes.\n\n![](/images/apps-sdk/preparing_authorization.png)\n\n4. ChatGPT exchanges the authorization code for an access token and attaches it to subsequent MCP requests (`Authorization: Bearer <token>`).\n\n![](/images/apps-sdk/auth_complete.png)\n\n5. Your server verifies the token on each request (issuer, audience, expiration, scopes) before executing the tool.\n\n### Client registration\n\nThe MCP spec currently requires dynamic client registration (DCR). This means that each time ChatGPT connects, it registers a fresh OAuth client with your authorization server, obtains a unique `client_id`, and uses that identity during token exchange. The downside of this approach is that it can generate thousands of short-lived clients—often one per user session.\n\nTo address this issue, the MCP council is currently advancing [Client Metadata Documents (CMID)](https://blog.modelcontextprotocol.io/posts/client_registration/). In the CMID model, ChatGPT will publish a stable document (for example `https://openai.com/chatgpt.json`) that declares its OAuth metadata and identity. Your authorization server can fetch the document over HTTPS, pin it as the canonical client record, and enforce policies such as redirect URI allowlists or rate limits without relying on per-session registration. CMID is still in draft, so continue supporting DCR until CIMD has landed.\n\n### Client identification\n\nA frequent question is how your MCP server can confirm that a request actually comes from ChatGPT. Today the only reliable control is network-level filtering, such as allowlisting ChatGPT’s [published egress IP ranges](https://openai.com/chatgpt-connectors.json). ChatGPT does **not** support machine-to-machine OAuth grants such as client credentials, service accounts, or JWT bearer assertions, nor can it present custom API keys or mTLS certificates.\n\nOnce rolled out, CMID directly addresses the client identification problem by giving you a signed, HTTPS-hosted declaration of ChatGPT’s identity.\n\n### Choosing an identity provider\n\nMost OAuth 2.1 identity providers can satisfy the MCP authorization requirements once they expose a discovery document, allow dynamic client registration, and echo the `resource` parameter into issued tokens.\n\nWe _strongly_ recommend that you use an existing established identity provider rather than implementing authentication from scratch yourself.\n\nHere are instructions for some popular identity providers.\n\n#### Auth0\n\n- [Guide to configuring Auth0 for MCP authorization](https://github.com/openai/openai-mcpkit/blob/main/python-authenticated-mcp-server-scaffold/README.md#2-configure-auth0-authentication)\n\n#### Stytch\n\n- [Guide to configuring Stytch for MCP authorization](https://stytch.com/docs/guides/connected-apps/mcp-server-overview)\n- [Overview guide to MCP authorization](https://stytch.com/blog/MCP-authentication-and-authorization-guide/)\n- [Overview guide to MCP authorization specifically for Apps SDK](https://stytch.com/blog/guide-to-authentication-for-the-openai-apps-sdk/)\n\n### Implementing token verification\n\nWhen the OAuth flow finishes, ChatGPT simply attaches the access token it received to subsequent MCP requests (`Authorization: Bearer …`). Once a request reaches your MCP server you must assume the token is untrusted and perform the full set of resource-server checks yourself—signature validation, issuer and audience matching, expiry, replay considerations, and scope enforcement. That responsibility sits with you, not with ChatGPT.\n\nIn practice you should:\n\n- Fetch the signing keys published by your authorization server (usually via JWKS) and verify the token’s signature and `iss`.\n- Reject tokens that have expired or have not yet become valid (`exp`/`nbf`).\n- Confirm the token was minted for your server (`aud` or the `resource` claim) and contains the scopes you marked as required.\n- Run any app-specific policy checks, then either attach the resolved identity to the request context or return a `401` with a `WWW-Authenticate` challenge.\n\nIf verification fails, respond with `401 Unauthorized` and a `WWW-Authenticate` header that points back to your protected-resource metadata. This tells the client to run the OAuth flow again.\n\n#### SDK token verification primitives\n\nBoth Python and TypeScript MCP SDKs include helpers so you do not have to wire this from scratch.\n\n- [Python](https://github.com/modelcontextprotocol/python-sdk?tab=readme-ov-file#authentication)\n- [TypeScript](https://github.com/modelcontextprotocol/typescript-sdk?tab=readme-ov-file#proxy-authorization-requests-upstream)',
    keywords: [
      "authorization",
      "chatgpt",
      "mcp",
      "https",
      "server",
      "oauth",
      "com",
      "resource",
      "metadata",
      "client",
      "token",
      "flow",
      "identity",
      "pkce",
      "sdk",
    ],
  },
  {
    id: "authentication-2",
    source: "Authentication",
    heading: "Testing and rollout",
    content:
      "- **Local testing** – start with a development tenant that issues short-lived tokens so you can iterate quickly.\n- **Dogfood** – once authentication works, gate access to trusted testers before rolling out broadly. You can require linking for specific tools or the entire connector.\n- **Rotation** – plan for token revocation, refresh, and scope changes. Your server should treat missing or stale tokens as unauthenticated and return a helpful error message.\n- **OAuth debugging** – use the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) Auth settings to walk through each OAuth step and pinpoint where the flow breaks before you ship.\n\nWith authentication in place you can confidently expose user-specific data and write actions to ChatGPT users.",
    keywords: [
      "tokens",
      "authentication",
      "before",
      "specific",
      "tools",
      "oauth",
      "inspector",
      "local",
      "testing",
      "start",
      "development",
      "tenant",
      "issues",
      "short",
      "lived",
    ],
  },
  {
    id: "authentication-3",
    source: "Authentication",
    heading: "Triggering authentication UI",
    content:
      'ChatGPT only surfaces its OAuth linking UI when your MCP server signals that OAuth is available or necessary.\n\nTriggering the tool-level OAuth flow requires both metadata (`securitySchemes` and the resource metadata document) **and** runtime errors that carry `_meta["mcp/www_authenticate"]`. Without both halves ChatGPT will not show the linking UI for that tool.\n\n1. **Publish resource metadata.** The MCP server must expose its OAuth configuration at a well-known URL such as `https://your-mcp.example.com/.well-known/oauth-protected-resource`.\n\n2. **Describe each tool’s auth policy with `securitySchemes`.** Declaring `securitySchemes` per tool tells ChatGPT which tools require OAuth versus which can run anonymously. Stick to per-tool declarations even if the entire server uses the same policy; server-level defaults make it difficult to evolve individual tools later.\n\n   Two scheme types are available today, and you can list more than one to express optional auth:\n   - `noauth` — the tool is callable anonymously; ChatGPT can run it immediately.\n   - `oauth2` — the tool needs an OAuth 2.0 access token; include the scopes you will request so the consent screen is accurate.\n\n   If you omit the array entirely, the tool inherits whatever default the server advertises. Declaring both `noauth` and `oauth2` tells ChatGPT it can start with anonymous calls but that linking unlocks privileged behavior. Regardless of what you signal to the client, your server must still verify the token, scopes, and audience on every invocation.\n\n   Example (public + optional auth) – TypeScript SDK\n\n   ```ts\n   declare const server: McpServer;\n\n   server.registerTool(\n     "search",\n     {\n       title: "Public Search",\n       description: "Search public documents.",\n       inputSchema: {\n         type: "object",\n         properties: { q: { type: "string" } },\n         required: ["q"],\n       },\n       securitySchemes: [\n         { type: "noauth" },\n         { type: "oauth2", scopes: ["search.read"] },\n       ],\n     },\n     async ({ input }) => {\n       return {\n         content: [{ type: "text", text: `Results for ${input.q}` }],\n         structuredContent: {},\n       };\n     },\n   );\n   ```\n\n   Example (auth required) – TypeScript SDK\n\n   ```ts\n   declare const server: McpServer;\n\n   server.registerTool(\n     "create_doc",\n     {\n       title: "Create Document",\n       description: "Make a new doc in your account.",\n       inputSchema: {\n         type: "object",\n         properties: { title: { type: "string" } },\n         required: ["title"],\n       },\n       securitySchemes: [{ type: "oauth2", scopes: ["docs.write"] }],\n     },\n     async ({ input }) => {\n       return {\n         content: [{ type: "text", text: `Created doc: ${input.title}` }],\n         structuredContent: {},\n       };\n     },\n   );\n   ```\n\n3. **Check tokens inside the tool handler and emit `_meta["mcp/www_authenticate"]`** when you want ChatGPT to trigger the authentication UI. Inspect the token and verify issuer, audience, expiry, and scopes. If no valid token is present, return an error result that includes `_meta["mcp/www_authenticate"]` and make sure the value contains both an `error` and `error_description` parameter. This `WWW-Authenticate` payload is what actually triggers the tool-level OAuth UI once steps 1 and 2 are in place.\n\n   Example\n\n   ```json\n   {\n     "jsonrpc": "2.0",\n     "id": 4,\n     "result": {\n       "content": [\n         {\n           "type": "text",\n           "text": "Authentication required: no access token provided."\n         }\n       ],\n       "_meta": {\n         "mcp/www_authenticate": [\n           "\'Bearer resource_metadata=\\"https://your-mcp.example.com/.well-known/oauth-protected-resource\\", error=\\"insufficient_scope\\", error_description=\\"You need to login to continue\\"\'"\n         ]\n       },\n       "isError": true\n     }\n   }\n   ```',
    keywords: [
      "server",
      "tool",
      "type",
      "oauth",
      "mcp",
      "chatgpt",
      "text",
      "securityschemes",
      "example",
      "token",
      "scopes",
      "title",
      "both",
      "resource",
      "_meta",
    ],
  },
  {
    id: "build-your-chatgpt-ui-0",
    source: "Build your ChatGPT UI",
    heading: "Overview",
    content:
      "UI components turn structured tool results from your MCP server into a human-friendly UI. Your components run inside an iframe in ChatGPT, talk to the host via the `window.openai` API, and render inline with the conversation. This guide describes how to structure your component project, bundle it, and wire it up to your MCP server.\n\nYou can also check out the [examples repository on GitHub](https://github.com/openai/openai-apps-sdk-examples).\n\n### Component library\n\nUse the optional UI kit at [apps-sdk-ui](https://openai.github.io/apps-sdk-ui) for ready-made buttons, cards, input controls, and layout primitives that match ChatGPT’s container. It saves time when you want consistent styling without rebuilding base components.",
    keywords: [
      "openai",
      "components",
      "github",
      "apps",
      "sdk",
      "mcp",
      "server",
      "chatgpt",
      "component",
      "examples",
      "https",
      "turn",
      "structured",
      "tool",
      "results",
    ],
  },
  {
    id: "build-your-chatgpt-ui-1",
    source: "Build your ChatGPT UI",
    heading: "Understand the `window.openai` API",
    content:
      'The host injects `window.openai` with UI-related globals and methods for calling tools, sending follow-ups, and managing layout. In your widget, read values directly from `window.openai` (e.g., `window.openai.toolOutput`, `window.openai.locale`) or through helper hooks like `useOpenAiGlobal` shown later.\n\n`window.openai` is the bridge between your frontend and ChatGPT. Use the quick reference below to understand the available data and APIs before you dive into component scaffolding.\n\n### List of capabilities\n\n| Capability          | What it does                                                                                                                                                                     | Typical use                                                                                       |\n| ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- |\n| State & data        | `window.openai.toolInput`                                                                                                                                                        | Arguments supplied when the tool was invoked.                                                     |\n| State & data        | `window.openai.toolOutput`                                                                                                                                                       | Your `structuredContent`. Keep fields concise; the model reads them verbatim.                     |\n| State & data        | `window.openai.toolResponseMetadata`                                                                                                                                             | The `_meta` payload; only the widget sees it, never the model.                                    |\n| State & data        | `window.openai.widgetState`                                                                                                                                                      | Snapshot of UI state persisted between renders.                                                   |\n| State & data        | `window.openai.setWidgetState(state)`                                                                                                                                            | Stores a new snapshot synchronously; call it after every meaningful UI interaction.               |\n| Widget runtime APIs | `window.openai.callTool(name, args)`                                                                                                                                             | Invoke another MCP tool from the widget (mirrors model-initiated calls).                          |\n| Widget runtime APIs | `window.openai.sendFollowUpMessage({ prompt })`                                                                                                                                  | Ask ChatGPT to post a message authored by the component.                                          |\n| Widget runtime APIs | `window.openai.uploadFile(file)`                                                                                                                                                 | Upload a user-selected file and receive a `fileId`.                                               |\n| Widget runtime APIs | `window.openai.getFileDownloadUrl({ fileId })`                                                                                                                                   | Retrieve a temporary download URL for a file uploaded by the widget or provided via file params.  |\n| Widget runtime APIs | `window.openai.requestDisplayMode(...)`                                                                                                                                          | Request PiP/fullscreen modes.                                                                     |\n| Widget runtime APIs | `window.openai.requestModal(...)`                                                                                                                                                | Spawn a modal owned by ChatGPT.                                                                   |\n| Widget runtime APIs | `window.openai.notifyIntrinsicHeight(...)`                                                                                                                                       | Report dynamic widget heights to avoid scroll clipping.                                           |\n| Widget runtime APIs | `window.openai.openExternal({ href })`                                                                                                                                           | Open a vetted external link in the user’s browser.                                                |\n| Context             | `window.openai.theme`, `window.openai.displayMode`, `window.openai.maxHeight`, `window.openai.safeArea`, `window.openai.view`, `window.openai.userAgent`, `window.openai.locale` | Environment signals you can read—or subscribe to via `useOpenAiGlobal`—to adapt visuals and copy. |\n\n### useOpenAiGlobal\n\nMany Apps SDK projects wrap `window.openai` access in small hooks so views remain testable. This example hook listens for host `openai:set_globals` events and lets React components subscribe to a single global value:\n\n```ts\nexport function useOpenAiGlobal<K extends keyof OpenAiGlobals>(\n  key: K,\n): OpenAiGlobals[K] {\n  return useSyncExternalStore(\n    (onChange) => {\n      const handleSetGlobal = (event: SetGlobalsEvent) => {\n        const value = event.detail.globals[key];\n        if (value === undefined) {\n          return;\n        }\n\n        onChange();\n      };\n\n      window.addEventListener(SET_GLOBALS_EVENT_TYPE, handleSetGlobal, {\n        passive: true,\n      });\n\n      return () => {\n        window.removeEventListener(SET_GLOBALS_EVENT_TYPE, handleSetGlobal);\n      };\n    },\n    () => window.openai[key],\n  );\n}\n```\n\n`useOpenAiGlobal` is an important primitive to make your app reactive to changes in display mode, theme, and "props" via subsequent tool calls.\n\nFor example, read the tool input, output, and metadata:\n\n```ts\nexport function useToolInput() {\n  return useOpenAiGlobal("toolInput");\n}\n\nexport function useToolOutput() {\n  return useOpenAiGlobal("toolOutput");\n}\n\nexport function useToolResponseMetadata() {\n  return useOpenAiGlobal("toolResponseMetadata");\n}\n```\n\n### Persist component state, expose context to ChatGPT\n\nWidget state can be used for persisting data across user sessions, and exposing data to ChatGPT. Anything you pass to `setWidgetState` will be shown to the model, and hydrated into `window.openai.widgetState`\n\nWidget state is scoped to the specific widget instance that lives on a single conversation message. When your component calls `window.openai.setWidgetState(payload)`, the host stores that payload under that widget’s `message_id/widgetId` pair and rehydrates it only for that widget. The state does not travel across the whole conversation or between different widgets.\n\nFollow-up turns keep the same widget (and therefore the same state) only when the user submits through that widget’s controls—inline follow-ups, PiP composer, or fullscreen composer. If the user types into the main chat composer, the request is treated as a new widget run with a fresh `widgetId` and empty `widgetState`.\n\nAnything you pass to `setWidgetState` is sent to the model, so keep the payload focused and well under 4k [tokens](https://platform.openai.com/tokenizer) for performance.\n\n### Trigger server actions\n\n`window.openai.callTool` lets the component directly make MCP tool calls. Use this for direct manipulations (refresh data, fetch nearby restaurants). Design tools to be idempotent where possible and return updated structured content that the model can reason over in subsequent turns.\n\nPlease note that your tool needs to be marked as [able to be initiated by the component](/apps-sdk/build/mcp-server###allow-component-initiated-tool-access).\n\n```tsx\nasync function refreshPlaces(city: string) {\n  await window.openai?.callTool("refresh_pizza_list", { city });\n}\n```\n\n### Send conversational follow-ups\n\nUse `window.openai.sendFollowUpMessage` to insert a message into the conversation as if the user asked it.\n\n```tsx\nawait window.openai?.sendFollowUpMessage({\n  prompt: "Draft a tasting itinerary for the pizzerias I favorited.",\n});\n```\n\n### Upload files from the widget\n\nUse `window.openai.uploadFile(file)` to upload a user-selected file and receive a `fileId`. This currently supports `image/png`, `image/jpeg`, and `image/webp`.\n\n```tsx\nfunction FileUploadInput() {\n  return (\n    <input\n      type="file"\n      accept="image/png,image/jpeg,image/webp"\n      onChange={async (event) => {\n        const file = event.currentTarget.files?.[0];\n        if (!file || !window.openai?.uploadFile) {\n          return;\n        }\n\n        const { fileId } = await window.openai.uploadFile(file);\n        console.log("Uploaded fileId:", fileId);\n      }}\n    />\n  );\n}\n```\n\n### Download files in the widget\n\nUse `window.openai.getFileDownloadUrl({ fileId })` to retrieve a temporary URL for files that were uploaded by the widget or passed to your tool via file params.\n\n```tsx\nconst { downloadUrl } = await window.openai.getFileDownloadUrl({ fileId });\nimageElement.src = downloadUrl;\n```\n\n### Close the widget\n\nYou can close the widget two ways: from the UI by calling `window.openai.requestClose()`, or from the server by having your tool response set `metadata.openai/closeWidget: true`, which instructs the host to hide the widget when that response arrives:\n\n```json\n{\n  "role": "tool",\n  "tool_call_id": "abc123",\n  "content": "...",\n  "metadata": {\n    "openai/closeWidget": true,\n    "openai/widgetDomain": "https://chatgpt.com",\n    "openai/widgetCSP": {\n      "connect_domains": ["https://chatgpt.com"],\n      "resource_domains": ["https://*.oaistatic.com"],\n      "frame_domains": ["https://*.example.com"] // Optional: allow iframes from these domains\n    }\n  }\n}\n```\n\nNote: By default, widgets cannot render subframes. Setting `frame_domains` relaxes this and allows your widget to embed iframes from those origins. Apps that use `frame_domains` are subject to stricter review and are likely to be rejected for broad distribution unless iframe content is core to the use case.\n\n### Widget session ID\n\nThe host includes a per-widget identifier in tool response metadata as `openai/widgetSessionId`. Use it to correlate multiple tool calls or logs for the same widget instance while it remains mounted.\n\n### Request alternate layouts\n\nIf the UI needs more space—like maps, tables, or embedded editors—ask the host to change the container. `window.openai.requestDisplayMode` negotiates inline, PiP, or fullscreen presentations.\n\n```tsx\nawait window.openai?.requestDisplayMode({ mode: "fullscreen" });\n// Note: on mobile, PiP may be coerced to fullscreen\n```\n\n### Use host-backed navigation\n\nSkybridge (the sandbox runtime) mirrors the iframe’s history into ChatGPT’s UI. Use standard routing APIs—such as React Router—and the host will keep navigation controls in sync with your component.\n\nRouter setup (React Router’s `BrowserRouter`):\n\n```ts\nexport default function PizzaListRouter() {\n  return (\n\n\n<Routes>\n        }>\n          } />\n        </Route>\n      </Routes>\n\n\n  );\n}\n```\n\nProgrammatic navigation:\n\n```ts\nconst navigate = useNavigate();\n\nfunction openDetails(placeId: string) {\n  navigate(`place/${placeId}`, { replace: false });\n}\n\nfunction closeDetails() {\n  navigate("..", { replace: true });\n}\n```',
    keywords: [
      "openai",
      "window",
      "widget",
      "state",
      "tool",
      "file",
      "apis",
      "return",
      "data",
      "runtime",
      "function",
      "host",
      "useopenaiglobal",
      "chatgpt",
      "component",
    ],
  },
  {
    id: "build-your-chatgpt-ui-2",
    source: "Build your ChatGPT UI",
    heading: "Scaffold the component project",
    content:
      "Now that you understand the `window.openai` API, it's time to scaffold your component project.\n\nAs best practice, keep the component code separate from your server logic. A common layout is:\n\n```\napp/\n  server/            # MCP server (Python or Node)\n  web/               # Component bundle source\n    package.json\n    tsconfig.json\n    src/component.tsx\n    dist/component.js   # Build output\n```\n\nCreate the project and install dependencies (Node 18+ recommended):\n\n```bash\ncd app/web\nnpm init -y\nnpm install react@^18 react-dom@^18\nnpm install -D typescript esbuild\n```\n\nIf your component requires drag-and-drop, charts, or other libraries, add them now. Keep the dependency set lean to reduce bundle size.",
    keywords: [
      "component",
      "server",
      "install",
      "npm",
      "now",
      "project",
      "keep",
      "app",
      "node",
      "web",
      "bundle",
      "json",
      "react",
      "understand",
      "window",
    ],
  },
  {
    id: "build-your-chatgpt-ui-3",
    source: "Build your ChatGPT UI",
    heading: "Author the React component",
    content:
      'Your entry file should mount a component into a `root` element and read initial data from `window.openai.toolOutput` or persisted state.\n\nWe have provided some example apps under the [examples page](./examples#pizzaz-list-source), for example, for a "Pizza list" app, which is a list of pizza restaurants.\n\n### Explore the Pizzaz component gallery\n\nWe provide a number of example components in the [Apps SDK examples](/apps-sdk/build/examples). Treat them as blueprints when shaping your own UI:\n\n- **Pizzaz List** – ranked card list with favorites and call-to-action buttons.  \n  ![Screenshot of the Pizzaz list component](/images/apps-sdk/pizzaz-list.png)\n- **Pizzaz Carousel** – embla-powered horizontal scroller that demonstrates media-heavy layouts.  \n  ![Screenshot of the Pizzaz carousel component](/images/apps-sdk/pizzaz-carousel.png)\n- **Pizzaz Map** – Mapbox integration with fullscreen inspector and host state sync.  \n  ![Screenshot of the Pizzaz map component](/images/apps-sdk/pizzaz-map.png)\n- **Pizzaz Album** – stacked gallery view built for deep dives on a single place.  \n  ![Screenshot of the Pizzaz album component](/images/apps-sdk/pizzaz-album.png)\n- **Pizzaz Video** – scripted player with overlays and fullscreen controls.\n\nEach example shows how to bundle assets, wire host APIs, and structure state for real conversations. Copy the one closest to your use case and adapt the data layer for your tool responses.\n\n### React helper hooks\n\nUsing `useOpenAiGlobal` in a `useWidgetState` hook to keep host-persisted widget state aligned with your local React state:\n\n```ts\nexport function useWidgetState<T extends WidgetState>(\n  defaultState: T | (() => T),\n): readonly [T, (state: SetStateAction<T>) => void];\nexport function useWidgetState<T extends WidgetState>(\n  defaultState?: T | (() => T | null) | null,\n): readonly [T | null, (state: SetStateAction<T | null>) => void];\nexport function useWidgetState<T extends WidgetState>(\n  defaultState?: T | (() => T | null) | null,\n): readonly [T | null, (state: SetStateAction<T | null>) => void] {\n  const widgetStateFromWindow = useWebplusGlobal("widgetState") as T;\n\n  const [widgetState, _setWidgetState] = useState<T | null>(() => {\n    if (widgetStateFromWindow != null) {\n      return widgetStateFromWindow;\n    }\n\n    return typeof defaultState === "function"\n      ? defaultState()\n      : (defaultState ?? null);\n  });\n\n  useEffect(() => {\n    _setWidgetState(widgetStateFromWindow);\n  }, [widgetStateFromWindow]);\n\n  const setWidgetState = useCallback(\n    (state: SetStateAction<T | null>) => {\n      _setWidgetState((prevState) => {\n        const newState = typeof state === "function" ? state(prevState) : state;\n\n        if (newState != null) {\n          window.openai.setWidgetState(newState);\n        }\n\n        return newState;\n      });\n    },\n    [window.openai.setWidgetState],\n  );\n\n  return [widgetState, setWidgetState] as const;\n}\n```\n\nThe hooks above make it easy to read the latest tool output, layout globals, or widget state directly from React components while still delegating persistence back to ChatGPT.',
    keywords: [
      "pizzaz",
      "state",
      "null",
      "apps",
      "list",
      "component",
      "sdk",
      "widgetstate",
      "defaultstate",
      "function",
      "const",
      "widgetstatefromwindow",
      "example",
      "examples",
      "screenshot",
    ],
  },
  {
    id: "build-your-chatgpt-ui-4",
    source: "Build your ChatGPT UI",
    heading: "Widget localization",
    content:
      'The host passes `locale` in `window.openai` and mirrors it to `document.documentElement.lang`. It is up to your widget to use that locale to load translations and format dates/numbers. A simple pattern with `react-intl`:\n\n```tsx\nconst messages: Record<string, Record<string, string>> = {\n  "en-US": en,\n  "es-ES": es,\n};\n\nexport function App() {\n  const locale = window.openai.locale ?? "en-US";\n  return {\n    /* Render UI with <FormattedMessage> or useIntl() */\n  };\n}\n```',
    keywords: [
      "locale",
      "string",
      "window",
      "openai",
      "const",
      "record",
      "host",
      "passes",
      "mirrors",
      "document",
      "documentelement",
      "lang",
      "widget",
      "load",
      "translations",
    ],
  },
  {
    id: "build-your-chatgpt-ui-5",
    source: "Build your ChatGPT UI",
    heading: "Bundle for the iframe",
    content:
      'Once you are done writing your React component, you can build it into a single JavaScript module that the server can inline:\n\n```json\n// package.json\n{\n  "scripts": {\n    "build": "esbuild src/component.tsx --bundle --format=esm --outfile=dist/component.js"\n  }\n}\n```\n\nRun `npm run build` to produce `dist/component.js`. If esbuild complains about missing dependencies, confirm you ran `npm install` in the `web/` directory and that your imports match installed package names (e.g., `@react-dnd/html5-backend` vs `react-dnd-html5-backend`).',
    keywords: [
      "component",
      "react",
      "build",
      "json",
      "package",
      "esbuild",
      "dist",
      "run",
      "npm",
      "dnd",
      "html5",
      "backend",
      "once",
      "done",
      "writing",
    ],
  },
  {
    id: "build-your-chatgpt-ui-6",
    source: "Build your ChatGPT UI",
    heading: "Embed the component in the server response",
    content:
      "See the [Set up your server docs](/apps-sdk/build/mcp-server#) for how to embed the component in your MCP server response.\n\nComponent UI templates are the recommended path for production.\n\nDuring development you can rebuild the component bundle whenever your React code changes and hot-reload the server.",
    keywords: [
      "server",
      "component",
      "mcp",
      "set",
      "docs",
      "apps",
      "sdk",
      "build",
      "embed",
      "response",
      "templates",
      "recommended",
      "path",
      "production",
      "during",
    ],
  },
  {
    id: "build-your-mcp-server-0",
    source: "Build your MCP server",
    heading: "Overview",
    content:
      "# Build your MCP server\n\nBy the end of this guide, you’ll know how to connect your backend MCP server to ChatGPT, define tools, register UI templates, and tie everything together using the widget runtime. You’ll build a working foundation for a ChatGPT App that returns structured data, renders an interactive widget, and keeps your model, server, and UI in sync. If you prefer to dive straight into the implementation, you can skip ahead to the [example](#example) at the end.",
    keywords: [
      "server",
      "build",
      "mcp",
      "end",
      "chatgpt",
      "widget",
      "example",
      "guide",
      "know",
      "connect",
      "backend",
      "define",
      "tools",
      "register",
      "templates",
    ],
  },
  {
    id: "build-your-mcp-server-1",
    source: "Build your MCP server",
    heading: "Overview",
    content:
      "### What an MCP server does for your app\n\nChatGPT Apps have three components:\n\n- **Your MCP server** defines tools, enforces auth, returns data, and points each tool to a UI bundle.\n- **The widget/UI bundle** renders inside ChatGPT’s iframe, reading data and widget-runtime globals exposed through `window.openai`.\n- **The model** decides when to call tools and narrates the experience using the structured data you return.\n\nA solid server implementation keeps those boundaries clean so you can iterate on UI and data independently. Remember: you build the MCP server and define the tools, but ChatGPT’s model chooses when to call them based on the metadata you provide.\n\n### Before you begin\n\nPre-requisites:\n\n- Comfortable with TypeScript or Python and a web bundler (Vite, esbuild, etc.).\n- MCP server reachable over HTTP (local is fine to start).\n- Built UI bundle that exports a root script (React or vanilla).\n\nExample project layout:\n\n```\nyour-chatgpt-app/\n├─ server/\n│  └─ src/index.ts          # MCP server + tool handlers\n├─ web/\n│  ├─ src/component.tsx     # React widget\n│  └─ dist/app.{js,css}  # Bundled assets referenced by the server\n└─ package.json\n```",
    keywords: [
      "server",
      "mcp",
      "chatgpt",
      "data",
      "app",
      "tools",
      "bundle",
      "widget",
      "tool",
      "model",
      "call",
      "web",
      "react",
      "src",
      "apps",
    ],
  },
  {
    id: "build-your-mcp-server-2",
    source: "Build your MCP server",
    heading: "Architecture flow",
    content:
      "1. A user prompt causes ChatGPT to call one of your MCP tools.\n2. Your server runs the handler, fetches authoritative data, and returns `structuredContent`, `_meta`, and UI metadata.\n3. ChatGPT loads the HTML template linked in the tool descriptor (served as `text/html+skybridge`) and injects the payload through `window.openai`.\n4. The widget renders from `window.openai.toolOutput`, persists UI state with `window.openai.setWidgetState`, and can call tools again via `window.openai.callTool`.\n5. The model reads `structuredContent` to narrate what happened, so keep it tight and idempotent—ChatGPT may retry tool calls.\n\n```\nUser prompt\n   ↓\nChatGPT model ──► MCP tool call ──► Your server ──► Tool response (`structuredContent`, `_meta`, `content`)\n   │                                                   │\n   └───── renders narration ◄──── widget iframe ◄──────┘\n                              (HTML template + `window.openai`)\n```",
    keywords: [
      "window",
      "openai",
      "chatgpt",
      "tool",
      "call",
      "structuredcontent",
      "html",
      "user",
      "prompt",
      "mcp",
      "tools",
      "server",
      "_meta",
      "template",
      "widget",
    ],
  },
  {
    id: "build-your-mcp-server-3",
    source: "Build your MCP server",
    heading: "Understand the `window.openai` widget runtime",
    content:
      "The sandboxed iframe exposes a single global object:\n\nKey capabilities include:\n\n- **State & data:** `toolInput`, `toolOutput`, `toolResponseMetadata`, and `widgetState` carry tool data and persisted UI state.\n- **Tool + messaging APIs:** `callTool` and `sendFollowUpMessage` let the widget invoke tools or post user-authored follow-ups.\n- **File handling:** `uploadFile` and `getFileDownloadUrl` cover image uploads and previews.\n- **Layout + host controls:** `requestDisplayMode`, `requestModal`, `notifyIntrinsicHeight`, and `openExternal` manage layout and host navigation.\n- **Context signals:** `theme`, `displayMode`, `maxHeight`, `safeArea`, `view`, `userAgent`, and `locale` let you adapt UI and copy.\n\nFor the full `window.openai` reference, see the [ChatGPT UI guide](/apps-sdk/build/chatgpt-ui#understand-the-windowopenai-api).\n\nUse `requestModal` when you need a host-controlled overlay—for example, open a checkout or detail view anchored to an “Add to cart” button so shoppers can review options without forcing the inline widget to resize.\n\nSubscribe to any of these fields with `useOpenAiGlobal` so multiple components stay in sync.\n\nHere's an example React component that reads `toolOutput` and persists UI state with `setWidgetState`:\nFor more information on how to build your UI, check out the [ChatGPT UI guide](https://developers.openai.com/apps-sdk/build/chatgpt-ui).\n\n```tsx\n// Example helper hook that keeps state\n// in sync with the widget runtime via window.openai.setWidgetState.\n\nexport function KanbanList() {\n  const [widgetState, setWidgetState] = useWidgetState(() => ({\n    selectedTask: null,\n  }));\n  const tasks = window.openai.toolOutput?.tasks ?? [];\n\n  return tasks.map((task) => (\n    <button\n      key={task.id}\n      data-selected={widgetState?.selectedTask === task.id}\n      onClick={() =>\n        setWidgetState((prev) => ({ ...prev, selectedTask: task.id }))\n      }\n    >\n      {task.title}\n    </button>\n  ));\n}\n```\n\nIf you're not using React, you don’t need a helper like useWidgetState. Vanilla JS widgets can read and write window.openai directly—for example, window.openai.toolOutput or window.openai.setWidgetState(state).",
    keywords: [
      "openai",
      "window",
      "state",
      "setwidgetstate",
      "task",
      "tooloutput",
      "chatgpt",
      "example",
      "data",
      "widgetstate",
      "widget",
      "host",
      "build",
      "button",
      "selectedtask",
    ],
  },
  {
    id: "build-your-mcp-server-4",
    source: "Build your MCP server",
    heading: "Pick an SDK",
    content:
      "Apps SDK works with any MCP implementation, but the official SDKs are the quickest way to get started. They ship tool/schema helpers, HTTP server scaffolding, resource registration utilities, and end-to-end type safety so you can stay focused on business logic:\n\n- **Python SDK** – Iterate quickly with FastMCP or FastAPI. Repo: [`modelcontextprotocol/python-sdk`](https://github.com/modelcontextprotocol/python-sdk).\n- **TypeScript SDK** – Ideal when your stack is already Node/React. Repo: [`modelcontextprotocol/typescript-sdk`](https://github.com/modelcontextprotocol/typescript-sdk), published as `@modelcontextprotocol/sdk`. Docs live on [modelcontextprotocol.io](https://modelcontextprotocol.io/).\n\nInstall whichever SDK matches your backend language, then follow the steps below.\n\n```bash\n# TypeScript / Node\nnpm install @modelcontextprotocol/sdk zod\n\n# Python\npip install mcp\n```",
    keywords: [
      "sdk",
      "modelcontextprotocol",
      "python",
      "typescript",
      "https",
      "install",
      "mcp",
      "end",
      "repo",
      "github",
      "com",
      "node",
      "apps",
      "works",
      "any",
    ],
  },
  {
    id: "build-your-mcp-server-5",
    source: "Build your MCP server",
    heading: "Build your MCP server",
    content:
      '### Step 1 – Register a component template\n\nEach UI bundle is exposed as an MCP resource whose `mimeType` is `text/html+skybridge`, signaling to ChatGPT that it should treat the payload as a sandboxed HTML entry point and inject the widget runtime. In other words, `text/html+skybridge` marks the file as a widget template instead of generic HTML.\n\nRegister the template and include metadata for borders, domains, and CSP rules:\n\n```ts\n// Registers the Kanban widget HTML entry point served to ChatGPT.\n\nconst server = new McpServer({ name: "kanban-server", version: "1.0.0" });\nconst HTML = readFileSync("web/dist/kanban.js", "utf8");\nconst CSS = readFileSync("web/dist/kanban.css", "utf8");\n\nserver.registerResource(\n  "kanban-widget",\n  "ui://widget/kanban-board.html",\n  {},\n  async () => ({\n    contents: [\n      {\n        uri: "ui://widget/kanban-board.html",\n        mimeType: "text/html+skybridge",\n        text: `\n<div id="kanban-root"></div>\n<style>${CSS}</style>\n<script type="module">${HTML}</script>\n        `.trim(),\n        _meta: {\n          "openai/widgetPrefersBorder": true,\n          "openai/widgetDomain": "https://chatgpt.com",\n          "openai/widgetCSP": {\n            connect_domains: ["https://chatgpt.com"], // example API domain\n            resource_domains: ["https://*.oaistatic.com"], // example CDN allowlist\n            // Optional: allow embedding specific iframe origins. See “frame_domains” docs.\n            frame_domains: ["https://*.example-embed.com"],\n          },\n        },\n      },\n    ],\n  }),\n);\n```\n\nIf you need to embed iframes inside your widget, use `frame_domains` to declare an allowlist of origins. Without `frame_domains` set, subframes are blocked by default. Because iframe content is harder for us to inspect, widgets that set `frame_domains` are reviewed with extra scrutiny and may not be approved for directory distribution.\n\n**Best practice:** When you change your widget’s HTML/JS/CSS in a breaking way, give the template a new URI (or use a new file name) so ChatGPT always loads the updated bundle instead of a cached one.\n\n### Step 2 – Describe tools\n\nTools are the contract the model reasons about. Define one tool per user intent (e.g., `list_tasks`, `update_task`). Each descriptor should include:\n\n- Machine-readable name and human-readable title.\n- JSON schema for arguments (`zod`, JSON Schema, or dataclasses).\n- `_meta["openai/outputTemplate"]` pointing to the template URI.\n- Optional `_meta` for invoking/invoked strings, `widgetAccessible`, read-only hints, etc.\n\n_The model inspects these descriptors to decide when a tool fits the user’s request, so treat names, descriptions, and schemas as part of your UX._\n\nDesign handlers to be **idempotent**—the model may retry calls.\n\n```ts\n// Example app that exposes a kanban-board tool with schema, metadata, and handler.\n\nserver.registerTool(\n  "kanban-board",\n  {\n    title: "Show Kanban Board",\n    inputSchema: { workspace: z.string() },\n    _meta: {\n      "openai/outputTemplate": "ui://widget/kanban-board.html",\n      "openai/toolInvocation/invoking": "Preparing the board…",\n      "openai/toolInvocation/invoked": "Board ready.",\n    },\n  },\n  async ({ workspace }) => {\n    const board = await loadBoard(workspace);\n    return {\n      structuredContent: board.summary,\n      content: [{ type: "text", text: `Showing board ${workspace}` }],\n      _meta: board.details,\n    };\n  },\n);\n```\n\n### Step 3 – Return structured data and metadata\n\nEvery tool response can include three sibling payloads:\n\n- **`structuredContent`** – concise JSON the widget uses _and_ the model reads. Include only what the model should see.\n- **`content`** – optional narration (Markdown or plaintext) for the model’s response.\n- **`_meta`** – large or sensitive data exclusively for the widget. `_meta` never reaches the model.\n\n```ts\n// Returns concise structuredContent for the model plus rich _meta for the widget.\nasync function loadKanbanBoard(workspace: string) {\n  const tasks = await db.fetchTasks(workspace);\n  return {\n    structuredContent: {\n      columns: ["todo", "in-progress", "done"].map((status) => ({\n        id: status,\n        title: status.replace("-", " "),\n        tasks: tasks.filter((task) => task.status === status).slice(0, 5),\n      })),\n    },\n    content: [\n      {\n        type: "text",\n        text: "Here\'s the latest snapshot. Drag cards in the widget to update status.",\n      },\n    ],\n    _meta: {\n      tasksById: Object.fromEntries(tasks.map((task) => [task.id, task])),\n      lastSyncedAt: new Date().toISOString(),\n    },\n  };\n}\n```\n\nThe widget reads those payloads through `window.openai.toolOutput` and `window.openai.toolResponseMetadata`, while the model only sees `structuredContent`/`content`.\n\n### Step 4 – Run locally\n\n1. Build your UI bundle (`npm run build` inside `web/`).\n2. Start the MCP server (Node, Python, etc.).\n3. Use [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) early and often to call `http://localhost:<port>/mcp`, list roots, and verify your widget renders correctly. Inspector mirrors ChatGPT’s widget runtime and catches issues before deployment.\n\nFor a TypeScript project, that usually looks like:\n\n```bash\nnpm run build       # compile server + widget\nnode dist/index.js  # start the compiled MCP server\n```\n\n### Step 5 – Expose an HTTPS endpoint\n\nChatGPT requires HTTPS. During development, tunnel localhost with ngrok (or similar):\n\n```bash\nngrok http <port>\n# Forwarding: https://<subdomain>.ngrok.app -> http://127.0.0.1:<port>\n```\n\nUse the ngrok URL when creating a connector in ChatGPT developer mode. For production, deploy to a low-latency HTTPS host (Cloudflare Workers, Fly.io, Vercel, AWS, etc.).',
    keywords: [
      "widget",
      "html",
      "kanban",
      "board",
      "_meta",
      "openai",
      "https",
      "model",
      "text",
      "chatgpt",
      "server",
      "workspace",
      "status",
      "step",
      "template",
    ],
  },
  {
    id: "build-your-mcp-server-6",
    source: "Build your MCP server",
    heading: "Example",
    content:
      'Here’s a stripped-down TypeScript server plus vanilla widget. For full projects, reference the public [Apps SDK examples](https://github.com/openai/openai-apps-sdk-examples).\n\n```ts\n// server/src/index.ts\n\nconst server = new McpServer({ name: "hello-world", version: "1.0.0" });\n\nserver.registerResource("hello", "ui://widget/hello.html", {}, async () => ({\n  contents: [\n    {\n      uri: "ui://widget/hello.html",\n      mimeType: "text/html+skybridge",\n      text: `\n<div id="root"></div>\n<script type="module" src="https://example.com/hello-widget.js"></script>\n      `.trim(),\n    },\n  ],\n}));\n\nserver.registerTool(\n  "hello_widget",\n  {\n    title: "Show hello widget",\n    inputSchema: { name: { type: "string" } },\n    _meta: { "openai/outputTemplate": "ui://widget/hello.html" },\n  },\n  async ({ name }) => ({\n    structuredContent: { message: `Hello ${name}!` },\n    content: [{ type: "text", text: `Greeting ${name}` }],\n    _meta: {},\n  }),\n);\n```\n\n```js\n// hello-widget.js\nconst root = document.getElementById("root");\nconst { message } = window.openai.toolOutput ?? { message: "Hi!" };\nroot.textContent = message;\n```',
    keywords: [
      "hello",
      "widget",
      "server",
      "name",
      "openai",
      "html",
      "text",
      "root",
      "message",
      "const",
      "type",
      "apps",
      "sdk",
      "examples",
      "https",
    ],
  },
  {
    id: "build-your-mcp-server-7",
    source: "Build your MCP server",
    heading: "Troubleshooting",
    content:
      '- **Widget doesn’t render** – Ensure the template resource returns `mimeType: "text/html+skybridge"` and that the bundled JS/CSS URLs resolve inside the sandbox.\n- **`window.openai` is undefined** – The host only injects the widget runtime for `text/html+skybridge` templates; double-check the MIME type and that the widget loaded without CSP violations.\n- **CSP or CORS failures** – Use `openai/widgetCSP` to allow the exact domains you fetch from; the sandbox blocks everything else.\n- **Stale bundles keep loading** – Cache-bust template URIs or file names whenever you deploy breaking changes.\n- **Structured payloads are huge** – Trim `structuredContent` to what the model truly needs; oversized payloads degrade model performance and slow rendering.',
    keywords: [
      "widget",
      "template",
      "text",
      "html",
      "skybridge",
      "sandbox",
      "openai",
      "csp",
      "payloads",
      "model",
      "doesn",
      "render",
      "ensure",
      "resource",
      "returns",
    ],
  },
  {
    id: "build-your-mcp-server-8",
    source: "Build your MCP server",
    heading: "Advanced capabilities",
    content:
      '### Component-initiated tool calls\n\nSet `_meta["openai/widgetAccessible"]` on the tool descriptor to `true` if the widget should call tools on its own (e.g., refresh data on a button click). That opt-in enables `window.openai.callTool`.\n\n```json\n"_meta": {\n  "openai/outputTemplate": "ui://widget/kanban-board.html",\n  "openai/widgetAccessible": true\n}\n```\n\n#### Tool visibility\n\nSet `_meta["openai/visibility"]` on the tool descriptor to `"private"` when a tool should be callable from your widget but hidden from the model. This helps avoid awkward prompts or unsafe UX. Visibility defaults to `"public"`; private tools still work with `window.openai.callTool`.\n\n```json\n"_meta": {\n  "openai/outputTemplate": "ui://widget/kanban-board.html",\n  "openai/widgetAccessible": true,\n  "openai/visibility": "private"\n}\n```\n\n### Files out (file params)\n\nIf your tool accepts user-provided files, declare file parameters with `_meta["openai/fileParams"]`. The value is a list of top-level input schema fields that should be treated as files. Nested file fields are not supported.\n\nEach file param must be an object with this shape:\n\n```json\n{\n  "download_url": "https://...",\n  "file_id": "file_..."\n}\n```\n\nExample:\n\n```ts\nserver.registerTool(\n  "process_image",\n  {\n    title: "process_image",\n    description: "Processes an image",\n    inputSchema: {\n      type: "object",\n      properties: {\n        imageToProcess: {\n          type: "object",\n          properties: {\n            download_url: { type: "string" },\n            file_id: { type: "string" },\n          },\n          required: ["download_url", "file_id"],\n          additionalProperties: false,\n        },\n      },\n      required: ["imageToProcess"],\n      additionalProperties: false,\n    },\n    _meta: {\n      "openai/outputTemplate": "ui://widget/widget.html",\n      "openai/fileParams": ["imageToProcess"],\n    },\n  },\n  async ({ imageToProcess }) => {\n    return {\n      content: [],\n      structuredContent: {\n        download_url: imageToProcess.download_url,\n        file_id: imageToProcess.file_id,\n      },\n    };\n  },\n);\n```\n\n### Content security policy (CSP)\n\nSet `_meta["openai/widgetCSP"]` on the widget resource so the sandbox knows which domains to allow for `connect-src`, `img-src`, `frame-src`, etc. This is required before broad distribution.\n\n```json\n"_meta": {\n  "openai/widgetCSP": {\n    connect_domains: ["https://api.example.com"],\n    resource_domains: ["https://persistent.oaistatic.com"],\n    frame_domains: ["https://*.example-embed.com"]\n  }\n}\n```\n\n- `connect_domains` – hosts your widget can fetch from.\n- `resource_domains` – hosts for static assets like images, fonts, and scripts.\n- `frame_domains` – optional; hosts your widget may embed as iframes. Widgets without `frame_domains` cannot render subframes.\n\nCaution: Using `frame_domains` is discouraged and should only be done when embedding iframes is core to your experience (for example, a code editor or notebook environment). Apps that declare `frame_domains` are subject to higher scrutiny at review time and are likely to be rejected or held back from broad distribution.\n\n### Widget domains\n\nSet `_meta["openai/widgetDomain"]` on the widget resource when you need a dedicated origin (e.g., for API key allowlists). ChatGPT renders the widget under `<domain>.web-sandbox.oaiusercontent.com`, which also enables the fullscreen punch-out button.\n\n```json\n"_meta": {\n  "openai/widgetCSP": {\n    connect_domains: ["https://api.example.com"],\n    resource_domains: ["https://persistent.oaistatic.com"]\n  },\n  "openai/widgetDomain": "https://chatgpt.com"\n}\n```\n\n### Component descriptions\n\nSet `_meta["openai/widgetDescription"]` on the widget resource to let the widget describe itself, reducing redundant text beneath the widget.\n\n```json\n"_meta": {\n  "openai/widgetCSP": {\n    connect_domains: ["https://api.example.com"],\n    resource_domains: ["https://persistent.oaistatic.com"]\n  },\n  "openai/widgetDomain": "https://chatgpt.com",\n  "openai/widgetDescription": "Shows an interactive zoo directory rendered by get_zoo_animals."\n}\n```\n\n### Localized content\n\nChatGPT sents the requested locale in `_meta["openai/locale"]` (with `_meta["webplus/i18n"]` as a legacy key) in the client request. Use RFC 4647 matching to select the closest supported locale, echo it back in your responses, and format numbers/dates accordingly.\n\n### Client context hints\n\nChatGPT may also sent hints in the client request metadata like `_meta["openai/userAgent"]` and `_meta["openai/userLocation"]`. These can be hepful for tailoring analytics or formatting, but **never** rely on them for authorization.\n\nOnce your templates, tools, and widget runtime are wired up, the fastest way to refine your app is to use ChatGPT itself: call your tools in a real conversation, watch your logs, and debug the widget with browser devtools. When everything looks good, put your MCP server behind HTTPS and your app is ready for users.',
    keywords: [
      "openai",
      "widget",
      "_meta",
      "https",
      "com",
      "tool",
      "json",
      "example",
      "imagetoprocess",
      "chatgpt",
      "set",
      "download_url",
      "file_id",
      "frame_domains",
      "tools",
    ],
  },
  {
    id: "build-your-mcp-server-9",
    source: "Build your MCP server",
    heading: "Security reminders",
    content:
      '- Treat `structuredContent`, `content`, `_meta`, and widget state as user-visible—never embed API keys, tokens, or secrets.\n- Do not rely on `_meta["openai/userAgent"]`, `_meta["openai/locale"]`, or other hints for authorization; enforce auth inside your MCP server and backing APIs.\n- Avoid exposing admin-only or destructive tools unless the server verifies the caller’s identity and intent.',
    keywords: [
      "_meta",
      "openai",
      "server",
      "treat",
      "structuredcontent",
      "content",
      "widget",
      "state",
      "user",
      "visible",
      "never",
      "embed",
      "api",
      "keys",
      "tokens",
    ],
  },
  {
    id: "connect-from-chatgpt-0",
    source: "Connect from ChatGPT",
    heading: "Before you begin",
    content:
      "You can test your app in ChatGPT with your account using [developer mode](https://platform.openai.com/docs/guides/developer-mode).\n\nPlease note that publishing your app for public access is not available at the moment, but we will accept submissions later this year. You can learn more in our [ChatGPT app review guidelines](/apps-sdk/app-developer-guidelines).\n\nTo turn on developer mode, navigate to **Settings → Apps & Connectors → Advanced settings (bottom of the page)**.\n\nFrom there, you can toggle developer mode if you organization allows it.\n\nOnce developer mode is active you will see a **Create** button under **Settings → Apps & Connectors**.\n\nAs of November 13th, 2025, ChatGPT Apps are supported on all plans, including\nBusiness, Enterprise, and Education plans.",
    keywords: [
      "developer",
      "mode",
      "app",
      "apps",
      "chatgpt",
      "settings",
      "guidelines",
      "connectors",
      "plans",
      "test",
      "account",
      "https",
      "platform",
      "openai",
      "com",
    ],
  },
  {
    id: "connect-from-chatgpt-1",
    source: "Connect from ChatGPT",
    heading: "Create a connector",
    content:
      "Once you have developer mode enabled, you can create a connector for your app in ChatGPT.\n\n1. Ensure your MCP server is reachable over HTTPS (for local development, you can expose a local server to the public internet via a tool such as [ngrok](https://ngrok.com/) or [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/)).\n2. In ChatGPT, navigate to **Settings → Connectors → Create**.\n3. Provide the metadata for your connector:\n   - **Connector name** – a user-facing title such as _Kanban board_.\n   - **Description** – explain what the connector does and when to use it. The model uses this text during discovery.\n   - **Connector URL** – the public `/mcp` endpoint of your server (for example `https://abc123.ngrok.app/mcp`).\n4. Click **Create**. If the connection succeeds you will see a list of the tools your server advertises. If it fails, refer to the [Testing](/apps-sdk/deploy/testing) guide to debug your app with MCP Inspector or the API Playground.",
    keywords: [
      "connector",
      "mcp",
      "server",
      "https",
      "create",
      "app",
      "ngrok",
      "cloudflare",
      "chatgpt",
      "local",
      "public",
      "such",
      "com",
      "testing",
      "once",
    ],
  },
  {
    id: "connect-from-chatgpt-2",
    source: "Connect from ChatGPT",
    heading: "Try the app",
    content:
      "Once your connector is created, you can try it out in a new ChatGPT conversation.\n\n1. Open a new chat in ChatGPT.\n2. Click the **+** button near the message composer, and click **More**.\n3. Choose the connector for your app in the list of available tools. This will add your app to the conversation context for the model to use.\n4. Prompt the model to invoke tools by saying related to your app. For example, “What are my available tasks?” for a Kanban board app.\n\nChatGPT will display tool-call payloads in the UI so you can confirm inputs and outputs. Write tools will require manual confirmation unless you choose to remember approvals for the conversation.",
    keywords: [
      "app",
      "chatgpt",
      "conversation",
      "tools",
      "connector",
      "new",
      "click",
      "choose",
      "available",
      "model",
      "once",
      "created",
      "try",
      "out",
      "open",
    ],
  },
  {
    id: "connect-from-chatgpt-3",
    source: "Connect from ChatGPT",
    heading: "Refreshing metadata",
    content:
      "Whenever you change your tools list or descriptions, you can refresh your MCP server's metadata in ChatGPT.\n\n1. Update your MCP server and redeploy it (unless you are using a local server).\n2. In **Settings → Connectors**, click into your connector and choose **Refresh**.\n3. Verify the tool list updates and try a few prompts to test the updated flows.",
    keywords: [
      "server",
      "list",
      "refresh",
      "mcp",
      "whenever",
      "change",
      "tools",
      "descriptions",
      "metadata",
      "chatgpt",
      "update",
      "redeploy",
      "unless",
      "local",
      "settings",
    ],
  },
  {
    id: "connect-from-chatgpt-4",
    source: "Connect from ChatGPT",
    heading: "Using other clients",
    content:
      "You can connect to your MCP server on other clients.\n\n- **API Playground** – visit the [platform playground](`https://platform.openai.com/chat`), and add your MCP server to the conversation: open **Tools → Add → MCP Server**, and paste the same HTTPS endpoint. This is useful when you want raw request/response logs.\n- **Mobile clients** – once the connector is linked on ChatGPT web, it will be available on ChatGPT mobile apps as well. Test mobile layouts early if your component has custom controls.\n\nWith the connector linked you can move on to validation, experiments, and eventual rollout.",
    keywords: [
      "mcp",
      "server",
      "mobile",
      "clients",
      "playground",
      "platform",
      "https",
      "add",
      "connector",
      "linked",
      "chatgpt",
      "connect",
      "other",
      "api",
      "visit",
    ],
  },
  {
    id: "define-tools-0",
    source: "Define tools",
    heading: "Tool-first thinking",
    content:
      "In Apps SDK, tools are the contract between your MCP server and the model. They describe what the connector can do, how to call it, and what data comes back. Good tool design makes discovery accurate, invocation reliable, and downstream UX predictable.\n\nUse the checklist below to turn your use cases into well-scoped tools before you touch the SDK.",
    keywords: [
      "sdk",
      "tools",
      "apps",
      "contract",
      "between",
      "mcp",
      "server",
      "model",
      "describe",
      "connector",
      "call",
      "data",
      "comes",
      "back",
      "good",
    ],
  },
  {
    id: "define-tools-1",
    source: "Define tools",
    heading: "Draft the tool surface area",
    content:
      'Start from the user journey defined in your [use case research](/apps-sdk/plan/use-case):\n\n- **One job per tool** – keep each tool focused on a single read or write action ("fetch_board", "create_ticket"), rather than a kitchen-sink endpoint. This helps the model decide between alternatives.\n- **Explicit inputs** – define the shape of `inputSchema` now, including parameter names, data types, and enums. Document defaults and nullable fields so the model knows what is optional.\n- **Predictable outputs** – enumerate the structured fields you will return, including machine-readable identifiers that the model can reuse in follow-up calls.\n\nIf you need both read and write behavior, create separate tools so ChatGPT can respect confirmation flows for write actions.',
    keywords: [
      "write",
      "model",
      "case",
      "tool",
      "read",
      "including",
      "fields",
      "start",
      "user",
      "journey",
      "defined",
      "research",
      "apps",
      "sdk",
      "plan",
    ],
  },
  {
    id: "define-tools-2",
    source: "Define tools",
    heading: "Capture metadata for discovery",
    content:
      'Discovery is driven almost entirely by metadata. For each tool, draft:\n\n- **Name** – action oriented and unique inside your connector (`kanban.move_task`).\n- **Description** – one or two sentences that start with "Use this when…" so the model knows exactly when to pick the tool.\n- **Parameter annotations** – describe each argument and call out safe ranges or enumerations. This context prevents malformed calls when the user prompt is ambiguous.\n- **Global metadata** – confirm you have app-level name, icon, and descriptions ready for the directory and launcher.\n\nLater, plug these into your MCP server and iterate using the [Optimize metadata](/apps-sdk/guides/optimize-metadata) workflow.',
    keywords: [
      "metadata",
      "each",
      "tool",
      "name",
      "optimize",
      "discovery",
      "driven",
      "almost",
      "entirely",
      "draft",
      "action",
      "oriented",
      "unique",
      "inside",
      "connector",
    ],
  },
  {
    id: "define-tools-3",
    source: "Define tools",
    heading: "Model-side guardrails",
    content:
      'Think through how the model should behave once a tool is linked:\n\n- **Prelinked vs. link-required** – if your app can work anonymously, mark tools as available without auth. Otherwise, make sure your connector enforces linking via the onboarding flow described in [Authentication](/apps-sdk/build/auth).\n- **Read-only hints** – set the [`readOnlyHint` annotation](https://modelcontextprotocol.io/specification/2025-11-25/schema#toolannotations) to specify tools which cannot mutate state.\n- **Destructive hints** - set the [`destructiveHint` annotation](https://modelcontextprotocol.io/specification/2025-11-25/schema#toolannotations) to specify which tools do delete or overwrite user data.\n- **Open-world hints** - set the [`openWorldHint` annotation](https://modelcontextprotocol.io/specification/2025-11-25/schema#toolannotations) to specify which tools publish content or reach outside the user\'s account.\n\n- **Result components** – decide whether each tool should render a component, return JSON only, or both. Setting `_meta["openai/outputTemplate"]` on the tool descriptor advertises the HTML template to ChatGPT.',
    keywords: [
      "tools",
      "tool",
      "hints",
      "set",
      "annotation",
      "https",
      "modelcontextprotocol",
      "specification",
      "2025",
      "schema",
      "toolannotations",
      "specify",
      "auth",
      "only",
      "user",
    ],
  },
  {
    id: "define-tools-4",
    source: "Define tools",
    heading: "Golden prompt rehearsal",
    content:
      "Before you implement, sanity-check your tool set against the prompt list you captured earlier:\n\n1. For every direct prompt, confirm you have exactly one tool that clearly addresses the request.\n2. For indirect prompts, ensure the tool descriptions give the model enough context to select your connector instead of a built-in alternative.\n3. For negative prompts, verify your metadata will keep the tool hidden unless the user explicitly opts in (e.g., by naming your product).\n\nCapture any gaps or ambiguities now and adjust the plan—changing metadata before launch is much cheaper than refactoring code later.",
    keywords: [
      "tool",
      "before",
      "prompt",
      "prompts",
      "metadata",
      "implement",
      "sanity",
      "check",
      "set",
      "against",
      "list",
      "captured",
      "earlier",
      "every",
      "direct",
    ],
  },
  {
    id: "define-tools-5",
    source: "Define tools",
    heading: "Handoff to implementation",
    content:
      "When you are ready to implement, compile the following into a handoff document:\n\n- Tool name, description, input schema, and expected output schema.\n- Whether the tool should return a component, and if so which UI component should render it.\n- Auth requirements, rate limits, and error handling expectations.\n- Test prompts that should succeed (and ones that should fail).\n\nBring this plan into the [Set up your server](/apps-sdk/build/mcp-server) guide to translate it into code with the MCP SDK of your choice.",
    keywords: [
      "tool",
      "schema",
      "component",
      "server",
      "sdk",
      "mcp",
      "ready",
      "implement",
      "compile",
      "following",
      "handoff",
      "document",
      "name",
      "description",
      "input",
    ],
  },
  {
    id: "deploy-your-app-0",
    source: "Deploy your app",
    heading: "Deployment options",
    content:
      "Once you have a working MCP server and component bundle, host them behind a stable HTTPS endpoint. Deployment platforms that work well with Apps SDK include:\n\n- **Managed containers** – Fly.io, Render, or Railway for quick spin-up and automatic TLS.\n- **Cloud serverless** – Google Cloud Run or Azure Container Apps if you need scale-to-zero, keeping in mind that long cold starts can interrupt streaming HTTP.\n- **Kubernetes** – for teams that already run clusters. Front your pods with an ingress controller that supports server-sent events.\n\nRegardless of platform, make sure `/mcp` stays responsive, supports streaming responses, and returns appropriate HTTP status codes for errors.",
    keywords: [
      "mcp",
      "server",
      "apps",
      "cloud",
      "run",
      "streaming",
      "http",
      "supports",
      "once",
      "working",
      "component",
      "bundle",
      "host",
      "them",
      "behind",
    ],
  },
  {
    id: "deploy-your-app-1",
    source: "Deploy your app",
    heading: "Local development",
    content:
      "During development you can expose your local server to ChatGPT using a tunnel such as ngrok:\n\n```bash\nngrok http 2091\n# https://<subdomain>.ngrok.app/mcp → http://127.0.0.1:2091/mcp\n```\n\nKeep the tunnel running while you iterate on your connector. When you change code:\n\n1. Rebuild the component bundle (`npm run build`).\n2. Restart your MCP server.\n3. Refresh the connector in ChatGPT settings to pull the latest metadata.",
    keywords: [
      "ngrok",
      "mcp",
      "server",
      "chatgpt",
      "tunnel",
      "http",
      "2091",
      "connector",
      "during",
      "development",
      "expose",
      "local",
      "such",
      "bash",
      "https",
    ],
  },
  {
    id: "deploy-your-app-2",
    source: "Deploy your app",
    heading: "Environment configuration",
    content:
      "- **Secrets** – store API keys or OAuth client secrets outside your repo. Use platform-specific secret managers and inject them as environment variables.\n- **Logging** – log tool-call IDs, request latency, and error payloads. This helps debug user reports once the connector is live.\n- **Observability** – monitor CPU, memory, and request counts so you can right-size your deployment.",
    keywords: [
      "secrets",
      "request",
      "store",
      "api",
      "keys",
      "oauth",
      "client",
      "outside",
      "repo",
      "platform",
      "specific",
      "secret",
      "managers",
      "inject",
      "them",
    ],
  },
  {
    id: "deploy-your-app-3",
    source: "Deploy your app",
    heading: "Dogfood and rollout",
    content:
      "Before launching broadly:\n\n1. **Gate access** – keep your connector behind developer mode or a Statsig experiment flag until you are confident in stability.\n2. **Run golden prompts** – exercise the discovery prompts you drafted during planning and note precision/recall changes with each release.\n3. **Capture artifacts** – record screenshots or screen captures showing the component in MCP Inspector and ChatGPT for reference.\n\nWhen you are ready for production, update directory metadata, confirm auth and storage are configured correctly, and publish change notes in [Release Notes](/apps-sdk/release-notes).",
    keywords: [
      "release",
      "notes",
      "prompts",
      "before",
      "launching",
      "broadly",
      "gate",
      "access",
      "keep",
      "connector",
      "behind",
      "developer",
      "mode",
      "statsig",
      "experiment",
    ],
  },
  {
    id: "deploy-your-app-4",
    source: "Deploy your app",
    heading: "Next steps",
    content:
      "- Connect your deployed endpoint to ChatGPT using the steps in [Connect from ChatGPT](/apps-sdk/deploy/connect-chatgpt).\n- Validate tooling and telemetry with the [Test your integration](/apps-sdk/deploy/testing) guide.\n- Keep a troubleshooting playbook handy via [Troubleshooting](/apps-sdk/deploy/troubleshooting) so on-call responders can quickly diagnose issues.",
    keywords: [
      "connect",
      "chatgpt",
      "apps",
      "sdk",
      "deploy",
      "troubleshooting",
      "deployed",
      "endpoint",
      "steps",
      "validate",
      "tooling",
      "telemetry",
      "test",
      "integration",
      "testing",
    ],
  },
  {
    id: "design-components-0",
    source: "Design components",
    heading: "Why components matter",
    content:
      "UI components are the human-visible half of your connector. They let users view or edit data inline, switch to fullscreen when needed, and keep context synchronized between typed prompts and UI actions. Planning them early ensures your MCP server returns the right structured data and component metadata from day one.",
    keywords: [
      "data",
      "components",
      "human",
      "visible",
      "half",
      "connector",
      "let",
      "users",
      "view",
      "edit",
      "inline",
      "switch",
      "fullscreen",
      "needed",
      "keep",
    ],
  },
  {
    id: "design-components-1",
    source: "Design components",
    heading: "Explore sample components",
    content:
      "We publish reusable examples in [openai-apps-sdk-examples](https://github.com/openai/openai-apps-sdk-examples) so you can see common patterns before you build your own. The pizzaz gallery covers every default surface we provide today:\n\n### List\n\nRenders dynamic collections with empty-state handling. [View the code](https://github.com/openai/openai-apps-sdk-examples/tree/main/src/pizzaz-list).\n\n![Screenshot of the Pizzaz list component](/images/apps-sdk/pizzaz-list.png)\n\n### Map\n\nPlots geo data with marker clustering and detail panes. [View the code](https://github.com/openai/openai-apps-sdk-examples/tree/main/src/pizzaz).\n\n![Screenshot of the Pizzaz map component](/images/apps-sdk/pizzaz-map.png)\n\n### Album\n\nShowcases media grids with fullscreen transitions. [View the code](https://github.com/openai/openai-apps-sdk-examples/tree/main/src/pizzaz-albums).\n\n![Screenshot of the Pizzaz album component](/images/apps-sdk/pizzaz-album.png)\n\n### Carousel\n\nHighlights featured content with swipe gestures. [View the code](https://github.com/openai/openai-apps-sdk-examples/tree/main/src/pizzaz-carousel).\n\n![Screenshot of the Pizzaz carousel component](/images/apps-sdk/pizzaz-carousel.png)\n\n### Shop\n\nDemonstrates product browsing with checkout affordances. [View the code](https://github.com/openai/openai-apps-sdk-examples/tree/main/src/pizzaz-shop).\n\n![Screenshot of the Pizzaz shop component in grid view](/images/apps-sdk/pizzaz-shop-view.png)\n![Screenshot of the Pizzaz shop component in modal view](/images/apps-sdk/pizzaz-shop-modal.png)",
    keywords: [
      "pizzaz",
      "openai",
      "apps",
      "sdk",
      "examples",
      "view",
      "https",
      "github",
      "com",
      "screenshot",
      "component",
      "images",
      "png",
      "shop",
      "code",
    ],
  },
  {
    id: "design-components-2",
    source: "Design components",
    heading: "Clarify the user interaction",
    content:
      "For each use case, decide what the user needs to see and manipulate:\n\n- **Viewer vs. editor** – is the component read-only (a chart, a dashboard) or should it support editing and writebacks (forms, kanban boards)?\n- **Single-shot vs. multiturn** – will the user accomplish the task in one invocation, or should state persist across turns as they iterate?\n- **Inline vs. fullscreen** – some tasks are comfortable in the default inline card, while others benefit from fullscreen or picture-in-picture modes. Sketch these states before you implement.\n\nWrite down the fields, affordances, and empty states you need so you can validate them with design partners and reviewers.",
    keywords: [
      "user",
      "inline",
      "fullscreen",
      "picture",
      "states",
      "each",
      "case",
      "decide",
      "needs",
      "manipulate",
      "viewer",
      "editor",
      "component",
      "read",
      "only",
    ],
  },
  {
    id: "design-components-3",
    source: "Design components",
    heading: "Map data requirements",
    content:
      "Components should receive everything they need in the tool response. When planning:\n\n- **Structured content** – define the JSON payload that the component will parse.\n- **Initial component state** – use `window.openai.toolOutput` as the initial render data. On subsequent followups that invoke `callTool`, use the return value of `callTool`. To cache state for re-rendering, you can use `window.openai.setWidgetState`.\n- **Auth context** – note whether the component should display linked-account information, or whether the model must prompt the user to connect first.\n\nFeeding this data through the MCP response is simpler than adding ad-hoc APIs later.",
    keywords: [
      "component",
      "response",
      "initial",
      "state",
      "window",
      "openai",
      "data",
      "calltool",
      "whether",
      "components",
      "receive",
      "everything",
      "need",
      "tool",
      "planning",
    ],
  },
  {
    id: "design-components-4",
    source: "Design components",
    heading: "Design for responsive layouts",
    content:
      "Components run inside an iframe on both desktop and mobile. Plan for:\n\n- **Adaptive breakpoints** – set a max width and design layouts that collapse gracefully on small screens.\n- **Accessible color and motion** – respect system dark mode (match color-scheme) and provide focus states for keyboard navigation.\n- **Launcher transitions** – if the user opens your component from the launcher or expands to fullscreen, make sure navigation elements stay visible.\n\nDocument CSS variables, font stacks, and iconography up front so they are consistent across components.",
    keywords: [
      "components",
      "color",
      "navigation",
      "launcher",
      "run",
      "inside",
      "iframe",
      "both",
      "desktop",
      "mobile",
      "plan",
      "adaptive",
      "breakpoints",
      "set",
      "max",
    ],
  },
  {
    id: "design-components-5",
    source: "Design components",
    heading: "Define the state contract",
    content:
      "Because components and the chat surface share conversation state, be explicit about what is stored where:\n\n- **Component state** – use the `window.openai.setWidgetState` API to persist state the host should remember (selected record, scroll position, staged form data).\n- **Server state** – store authoritative data in your backend or the built-in storage layer. Decide how to merge server changes back into component state after follow-up tool calls.\n- **Model messages** – think about what human-readable updates the component should send back via `sendFollowUpMessage` so the transcript stays meaningful.\n\nCapturing this state diagram early prevents hard-to-debug sync issues later.",
    keywords: [
      "state",
      "component",
      "data",
      "server",
      "back",
      "because",
      "components",
      "chat",
      "surface",
      "share",
      "conversation",
      "explicit",
      "stored",
      "window",
      "openai",
    ],
  },
  {
    id: "design-components-6",
    source: "Design components",
    heading: "Plan telemetry and debugging hooks",
    content:
      "Inline experiences are hardest to debug without instrumentation. Decide in advance how you will:\n\n- Emit analytics events for component loads, button clicks, and validation errors.\n- Log tool-call IDs alongside component telemetry so you can trace issues end to end.\n- Provide fallbacks when the component fails to load (e.g., show the structured JSON and prompt the user to retry).\n\nOnce these plans are in place you are ready to move on to the implementation details in [Build a ChatGPT UI](/apps-sdk/build/chatgpt-ui).",
    keywords: [
      "component",
      "end",
      "build",
      "chatgpt",
      "inline",
      "experiences",
      "hardest",
      "debug",
      "without",
      "instrumentation",
      "decide",
      "advance",
      "emit",
      "analytics",
      "events",
    ],
  },
  {
    id: "mcp-0",
    source: "MCP",
    heading: "What is MCP?",
    content:
      "The [Model Context Protocol](https://modelcontextprotocol.io/) (MCP) is an open specification for connecting large language model clients to external tools and resources. An MCP server exposes **tools** that a model can call during a conversation, and return results given specified parameters.\nOther resources (metadata) can be returned along with tool results, including the inline html that we can use in the Apps SDK to render an interface.\n\nWith Apps SDK, MCP is the backbone that keeps server, model, and UI in sync. By standardising the wire format, authentication, and metadata, it lets ChatGPT reason about your app the same way it reasons about built-in tools.",
    keywords: [
      "model",
      "mcp",
      "tools",
      "resources",
      "server",
      "results",
      "metadata",
      "apps",
      "sdk",
      "context",
      "protocol",
      "https",
      "modelcontextprotocol",
      "open",
      "specification",
    ],
  },
  {
    id: "mcp-1",
    source: "MCP",
    heading: "Protocol building blocks",
    content:
      "A minimal MCP server for Apps SDK implements three capabilities:\n\n1. **List tools** – your server advertises the tools it supports, including their JSON Schema input and output contracts and optional annotations.\n2. **Call tools** – when a model selects a tool to use, it sends a `call_tool` request with the arguments corresponding to the user intent. Your server executes the action and returns structured content the model can parse.\n3. **Return components** – in addition to structured content returned by the tool, each tool (in its metadata) can optionally point to an [embedded resource](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#embedded-resources) that represents the interface to render in the ChatGPT client.\n\nThe protocol is transport agnostic, you can host the server over Server-Sent Events or Streamable HTTP. Apps SDK supports both options, but we recommend Streamable HTTP.",
    keywords: [
      "server",
      "tools",
      "tool",
      "apps",
      "sdk",
      "supports",
      "model",
      "structured",
      "content",
      "embedded",
      "streamable",
      "http",
      "minimal",
      "mcp",
      "implements",
    ],
  },
  {
    id: "mcp-2",
    source: "MCP",
    heading: "Why Apps SDK standardises on MCP",
    content:
      "Working through MCP gives you several benefits out of the box:\n\n- **Discovery integration** – the model consumes your tool metadata and surface descriptions the same way it does for first-party connectors, enabling natural-language discovery and launcher ranking. See [Discovery](/apps-sdk/concepts/user-interaction) for details.\n- **Conversation awareness** – structured content and component state flow through the conversation. The model can inspect the JSON result, refer to IDs in follow-up turns, or render the component again later.\n- **Multiclient support** – MCP is self-describing, so your connector works across ChatGPT web and mobile without custom client code.\n- **Extensible auth** – the specification includes protected resource metadata, OAuth 2.1 flows, and dynamic client registration so you can control access without inventing a proprietary handshake.",
    keywords: [
      "discovery",
      "through",
      "mcp",
      "model",
      "metadata",
      "conversation",
      "component",
      "without",
      "client",
      "working",
      "gives",
      "several",
      "benefits",
      "out",
      "box",
    ],
  },
  {
    id: "mcp-3",
    source: "MCP",
    heading: "Next steps",
    content:
      "If you're new to MCP, we recommend starting with the following resources:\n\n- [Model Context Protocol specification](https://modelcontextprotocol.io/specification)\n- Official SDKs: [Python SDK (official; includes FastMCP module)](https://github.com/modelcontextprotocol/python-sdk) and [TypeScript](https://github.com/modelcontextprotocol/typescript-sdk)\n- [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for local debugging\n\nOnce you are comfortable with the MCP primitives, you can move on to the [Set up your server](/apps-sdk/build/mcp-server) guide for implementation details.",
    keywords: [
      "mcp",
      "https",
      "modelcontextprotocol",
      "sdk",
      "specification",
      "official",
      "python",
      "github",
      "com",
      "typescript",
      "inspector",
      "server",
      "new",
      "recommend",
      "starting",
    ],
  },
  {
    id: "managing-state-0",
    source: "Managing State",
    heading: "Managing State in ChatGPT Apps",
    content:
      "This guide explains how to manage state for custom UI components rendered inside ChatGPT when building an app using the Apps SDK and an MCP server. You’ll learn how to decide where each piece of state belongs and how to persist it across renders and conversations.",
    keywords: [
      "state",
      "guide",
      "explains",
      "manage",
      "custom",
      "components",
      "rendered",
      "inside",
      "chatgpt",
      "building",
      "app",
      "apps",
      "sdk",
      "mcp",
      "server",
    ],
  },
  {
    id: "managing-state-1",
    source: "Managing State",
    heading: "Overview",
    content:
      "State in a ChatGPT app falls into three categories:\n\n| State type                        | Owned by                           | Lifetime                             | Examples                                      |\n| --------------------------------- | ---------------------------------- | ------------------------------------ | --------------------------------------------- |\n| **Business data (authoritative)** | MCP server or backend service      | Long-lived                           | Tasks, tickets, documents                     |\n| **UI state (ephemeral)**          | The widget instance inside ChatGPT | Only for the active widget           | Selected row, expanded panel, sort order      |\n| **Cross-session state (durable)** | Your backend or storage            | Cross-session and cross-conversation | Saved filters, view mode, workspace selection |\n\nPlace every piece of state where it belongs so the UI stays consistent and the chat matches the expected intent.\n\n---",
    keywords: [
      "state",
      "cross",
      "chatgpt",
      "backend",
      "widget",
      "session",
      "app",
      "falls",
      "three",
      "categories",
      "type",
      "owned",
      "lifetime",
      "examples",
      "business",
    ],
  },
  {
    id: "managing-state-2",
    source: "Managing State",
    heading: "How UI Components Live Inside ChatGPT",
    content:
      "When your app returns a custom UI component, ChatGPT renders that component inside a widget that is tied to a specific message in the conversation. The widget persists as long as that message exists in the thread.\n\n**Key behavior:**\n\n- **Widgets are message-scoped:** Every response that returns a widget creates a fresh instance with its own UI state.\n- **UI state sticks with the widget:** When you reopen or refresh the same message, the widget restores its saved state (selected row, expanded panel, etc.).\n- **Server data drives the truth:** The widget only sees updated business data when a tool call completes, and then it reapplies its local UI state on top of that snapshot.\n\n### Mental model\n\nThe widget’s UI and data layers work together like this:\n\n```text\nServer (MCP or backend)\n│\n├── Authoritative business data (source of truth)\n│\n▼\nChatGPT Widget\n│\n├── Ephemeral UI state (visual behavior)\n│\n└── Rendered view = authoritative data + UI state\n```\n\nThis separation keeps UI interaction smooth while ensuring data correctness.\n\n---",
    keywords: [
      "widget",
      "state",
      "data",
      "message",
      "returns",
      "component",
      "chatgpt",
      "behavior",
      "server",
      "truth",
      "business",
      "authoritative",
      "app",
      "custom",
      "renders",
    ],
  },
  {
    id: "managing-state-3",
    source: "Managing State",
    heading: "1. Business State (Authoritative)",
    content:
      'Business data is the **source of truth**.  \nIt should live on your MCP server or backend, not inside the widget.\n\nWhen the user takes an action:\n\n1. The UI calls a server tool.\n2. The server updates data.\n3. The server returns the new authoritative snapshot.\n4. The widget re-renders using that snapshot.\n\nThis prevents divergence between UI and server.\n\n### Example: Returning authoritative state from an MCP server (Node.js)\n\n```js\nconst tasks = new Map(); // replace with your DB or external service\nlet nextId = 1;\n\nconst server = new Server({\n  tools: {\n    get_tasks: {\n      description: "Return all tasks",\n      inputSchema: jsonSchema.object({}),\n      async run() {\n        return {\n          structuredContent: {\n            type: "taskList",\n            tasks: Array.from(tasks.values()),\n          },\n        };\n      },\n    },\n    add_task: {\n      description: "Add a new task",\n      inputSchema: jsonSchema.object({ title: jsonSchema.string() }),\n      async run({ title }) {\n        const id = `task-${nextId++}`; // simple example id\n        tasks.set(id, { id, title, done: false });\n\n        // Always return updated authoritative state\n        return this.tools.get_tasks.run({});\n      },\n    },\n  },\n});\n\nserver.start();\n```\n\n---',
    keywords: [
      "server",
      "tasks",
      "new",
      "return",
      "authoritative",
      "const",
      "jsonschema",
      "run",
      "title",
      "data",
      "mcp",
      "widget",
      "snapshot",
      "example",
      "state",
    ],
  },
  {
    id: "managing-state-4",
    source: "Managing State",
    heading: "2. UI State (Ephemeral)",
    content:
      'UI state describes **how** data is being viewed, not the data itself.\n\nWidgets do not automatically re-sync UI state when new server data arrives. Instead, the widget keeps its UI state and re-applies it when authoritative data is refreshed.\n\nStore UI state inside the widget instance using:\n\n- `window.openai.widgetState` – read the current widget-scoped state snapshot.\n- `window.openai.setWidgetState(newState)` – write the next snapshot. The call is synchronous; persistence happens in the background.\n\nReact apps should use the provided `useWidgetState` hook instead of reading globals directly. The hook:\n\n- Hydrates initial state from `window.openai.widgetState` (or the initializer you pass in).\n- Subscribes to future updates via `useOpenAiGlobal("widgetState")`.\n- Mirrors writes back through `window.openai.setWidgetState`, so the widget stays in sync even if multiple components mutate the same state.\n\nBecause the host persists widget state asynchronously, there is nothing to `await` when you call `window.openai.setWidgetState`. Treat it just like updating local component state and call it immediately after every meaningful UI-state change.\n\n### Example (React component)\n\nThis example assumes you copied the `useWidgetState` helper from the [ChatGPT UI guide](/apps-sdk/build/chatgpt-ui) (or defined it yourself) and are importing it from your project.\n\n```tsx\nexport function TaskList({ data }) {\n  const [widgetState, setWidgetState] = useWidgetState(() => ({\n    selectedId: null,\n  }));\n\n  const selectTask = (id) => {\n    setWidgetState((prev) => ({ ...prev, selectedId: id }));\n  };\n\n  return (\n    <ul>\n      {data.tasks.map((task) => (\n        <li\n          key={task.id}\n          style={{\n            fontWeight: widgetState?.selectedId === task.id ? "bold" : "normal",\n          }}\n          onClick={() => selectTask(task.id)}\n        >\n          {task.title}\n        </li>\n      ))}\n    </ul>\n  );\n}\n```\n\n### Example (vanilla JS component)\n\n```js\nconst tasks = window.openai.toolOutput?.tasks ?? [];\nlet widgetState = window.openai.widgetState ?? { selectedId: null };\n\nfunction selectTask(id) {\n  widgetState = { ...widgetState, selectedId: id };\n  window.openai.setWidgetState(widgetState);\n  renderTasks();\n}\n\nfunction renderTasks() {\n  const list = document.querySelector("#task-list");\n  list.innerHTML = tasks\n    .map(\n      (task) => `\n        <li\n          style="font-weight: ${widgetState.selectedId === task.id ? "bold" : "normal"}"\n          onclick="selectTask(\'${task.id}\')"\n        >\n          ${task.title}\n        </li>\n      `,\n    )\n    .join("");\n}\n\nrenderTasks();\n```\n\n### Image IDs in widget state (model-visible images)\n\nIf your widget works with images, use the structured widget state shape and include an `imageIds` array. The host will expose these file IDs to the model on follow-up turns so the model can reason about the images.\n\nThe recommended shape is:\n\n- `modelContent`: text or JSON the model should see.\n- `privateContent`: UI-only state the model should not see.\n- `imageIds`: list of file IDs uploaded by the widget or provided to your tool via file params.\n\n```tsx\ntype StructuredWidgetState = {\n  modelContent: string | Record<string, unknown> | null;\n  privateContent: Record<string, unknown> | null;\n  imageIds: string[];\n};\n\nconst [state, setState] = useWidgetState<StructuredWidgetState>(null);\n\nsetState({\n  modelContent: "Check out the latest updated image",\n  privateContent: {\n    currentView: "image-viewer",\n    filters: ["crop", "sharpen"],\n  },\n  imageIds: ["file_123", "file_456"],\n});\n```\n\nOnly file IDs you uploaded with `window.openai.uploadFile` or received via file params can be included in `imageIds`.\n\n---',
    keywords: [
      "state",
      "widgetstate",
      "task",
      "widget",
      "window",
      "openai",
      "data",
      "setwidgetstate",
      "selectedid",
      "const",
      "null",
      "model",
      "imageids",
      "file",
      "usewidgetstate",
    ],
  },
  {
    id: "managing-state-5",
    source: "Managing State",
    heading: "3. Cross-session state",
    content:
      "Preferences that must persist across conversations, devices, or sessions should be stored in your backend.\n\nApps SDK handles conversation state automatically, but most real-world apps also need durable storage. You might cache fetched data, keep track of user preferences, or persist artifacts created inside a component. Choosing to add a storage layer adds additional capabilities, but also complexity.",
    keywords: [
      "preferences",
      "persist",
      "apps",
      "storage",
      "across",
      "conversations",
      "devices",
      "sessions",
      "stored",
      "backend",
      "sdk",
      "handles",
      "conversation",
      "state",
      "automatically",
    ],
  },
  {
    id: "managing-state-6",
    source: "Managing State",
    heading: "Bring your own backend",
    content:
      'If you already run an API or need multi-user collaboration, integrate with your existing storage layer. In this model:\n\n- Authenticate the user via OAuth (see [Authentication](/apps-sdk/build/auth)) so you can map ChatGPT identities to your internal accounts.\n- Use your backend’s APIs to fetch and mutate data. Keep latency low; users expect components to render in a few hundred milliseconds.\n- Return sufficient structured content so the model can understand the data even if the component fails to load.\n\nWhen you roll your own storage, plan for:\n\n- **Data residency and compliance** – ensure you have agreements in place before transferring PII or regulated data.\n- **Rate limits** – protect your APIs against bursty traffic from model retries or multiple active components.\n- **Versioning** – include schema versions in stored objects so you can migrate them without breaking existing conversations.\n\n### Example: Widget invokes a tool\n\n```tsx\nexport function PreferencesForm({ userId, initialPreferences }) {\n  const [formState, setFormState] = useState(initialPreferences);\n  const [isSaving, setIsSaving] = useState(false);\n\n  async function savePreferences(next) {\n    setIsSaving(true);\n    setFormState(next);\n    window.openai.setWidgetState(next);\n\n    const result = await window.openai.callTool("set_preferences", {\n      userId,\n      preferences: next,\n    });\n\n    const updated = result?.structuredContent?.preferences ?? next;\n    setFormState(updated);\n    window.openai.setWidgetState(updated);\n    setIsSaving(false);\n  }\n\n  return (\n    <form>\n      {/* form fields bound to formState */}\n      <button\n        type="button"\n        disabled={isSaving}\n        onClick={() => savePreferences(formState)}\n      >\n        {isSaving ? "Saving…" : "Save preferences"}\n      </button>\n    </form>\n  );\n}\n```\n\n### Example: Server handles the tool (Node.js)\n\n```js\n// Helpers that call your existing backend API\nasync function readPreferences(userId) {\n  const response = await request(\n    `https://api.example.com/users/${userId}/preferences`,\n    {\n      method: "GET",\n      headers: { Authorization: `Bearer ${process.env.API_TOKEN}` },\n    },\n  );\n  if (response.statusCode === 404) return {};\n  if (response.statusCode >= 400) throw new Error("Failed to load preferences");\n  return await response.body.json();\n}\n\nasync function writePreferences(userId, preferences) {\n  const response = await request(\n    `https://api.example.com/users/${userId}/preferences`,\n    {\n      method: "PUT",\n      headers: {\n        Authorization: `Bearer ${process.env.API_TOKEN}`,\n        "Content-Type": "application/json",\n      },\n      body: JSON.stringify(preferences),\n    },\n  );\n  if (response.statusCode >= 400) throw new Error("Failed to save preferences");\n  return await response.body.json();\n}\n\nconst server = new Server({\n  tools: {\n    get_preferences: {\n      inputSchema: jsonSchema.object({ userId: jsonSchema.string() }),\n      async run({ userId }) {\n        const preferences = await readPreferences(userId);\n        return { structuredContent: { type: "preferences", preferences } };\n      },\n    },\n    set_preferences: {\n      inputSchema: jsonSchema.object({\n        userId: jsonSchema.string(),\n        preferences: jsonSchema.object({}),\n      }),\n      async run({ userId, preferences }) {\n        const updated = await writePreferences(userId, preferences);\n        return {\n          structuredContent: { type: "preferences", preferences: updated },\n        };\n      },\n    },\n  },\n});\n```\n\n---',
    keywords: [
      "preferences",
      "userid",
      "const",
      "return",
      "await",
      "response",
      "async",
      "next",
      "updated",
      "jsonschema",
      "api",
      "data",
      "example",
      "function",
      "type",
    ],
  },
  {
    id: "managing-state-7",
    source: "Managing State",
    heading: "Summary",
    content:
      "- Store **business data** on the server.\n- Store **UI state** inside the widget using `window.openai.widgetState`, `window.openai.setWidgetState`, or the `useWidgetState` hook.\n- Store **cross-session state** in backend storage you control.\n- Widget state persists only for the widget instance belonging to a specific message.\n- Avoid using `localStorage` for core state.",
    keywords: [
      "state",
      "store",
      "widget",
      "window",
      "openai",
      "business",
      "data",
      "server",
      "inside",
      "widgetstate",
      "setwidgetstate",
      "usewidgetstate",
      "hook",
      "cross",
      "session",
    ],
  },
  {
    id: "optimize-metadata-0",
    source: "Optimize Metadata",
    heading: "Why metadata matters",
    content:
      "ChatGPT decides when to call your connector based on the metadata you provide. Well-crafted names, descriptions, and parameter docs increase recall on relevant prompts and reduce accidental activations. Treat metadata like product copy—it needs iteration, testing, and analytics.",
    keywords: [
      "metadata",
      "chatgpt",
      "decides",
      "call",
      "connector",
      "based",
      "provide",
      "well",
      "crafted",
      "names",
      "descriptions",
      "parameter",
      "docs",
      "increase",
      "recall",
    ],
  },
  {
    id: "optimize-metadata-1",
    source: "Optimize Metadata",
    heading: "Gather a golden prompt set",
    content:
      "Before you tune metadata, assemble a labelled dataset:\n\n- **Direct prompts** – users explicitly name your product or data source.\n- **Indirect prompts** – users describe the outcome they want without naming your tool.\n- **Negative prompts** – cases where built-in tools or other connectors should handle the request.\n\nDocument the expected behaviour for each prompt (call your tool, do nothing, or use an alternative). You will reuse this set during regression testing.",
    keywords: [
      "prompts",
      "users",
      "tool",
      "before",
      "tune",
      "metadata",
      "assemble",
      "labelled",
      "dataset",
      "direct",
      "explicitly",
      "name",
      "product",
      "data",
      "source",
    ],
  },
  {
    id: "optimize-metadata-2",
    source: "Optimize Metadata",
    heading: "Draft metadata that guides the model",
    content:
      'For each tool:\n\n- **Name** – pair the domain with the action (`calendar.create_event`).\n- **Description** – start with “Use this when…” and call out disallowed cases ("Do not use for reminders").\n- **Parameter docs** – describe each argument, include examples, and use enums for constrained values.\n- **Read-only hint** – annotate `readOnlyHint: true` on tools that never mutate state so ChatGPT can streamline confirmation.\n- For tools that are not read-only:\n  - **Destructive hint** - annotate `destructiveHint: false` on tools that do not delete or overwrite user data.\n  - **Open-world hint** - annotate `openWorldHint: false` on tools that do not publish content or reach outside the user\'s account.',
    keywords: [
      "not",
      "tools",
      "hint",
      "annotate",
      "each",
      "read",
      "only",
      "false",
      "user",
      "tool",
      "name",
      "pair",
      "domain",
      "action",
      "calendar",
    ],
  },
  {
    id: "optimize-metadata-3",
    source: "Optimize Metadata",
    heading: "Evaluate in developer mode",
    content:
      "1. Link your connector in ChatGPT developer mode.\n2. Run through the golden prompt set and record the outcome: which tool was selected, what arguments were passed, and whether the component rendered.\n3. For each prompt, track precision (did the right tool run?) and recall (did the tool run when it should?).\n\nIf the model picks the wrong tool, revise the descriptions to emphasise the intended scenario or narrow the tool’s scope.",
    keywords: [
      "tool",
      "run",
      "prompt",
      "link",
      "connector",
      "chatgpt",
      "developer",
      "mode",
      "through",
      "golden",
      "set",
      "record",
      "outcome",
      "selected",
      "arguments",
    ],
  },
  {
    id: "optimize-metadata-4",
    source: "Optimize Metadata",
    heading: "Iterate methodically",
    content:
      "- Change one metadata field at a time so you can attribute improvements.\n- Keep a log of revisions with timestamps and test results.\n- Share diffs with reviewers to catch ambiguous copy before you deploy it.\n\nAfter each revision, repeat the evaluation. Aim for high precision on negative prompts before chasing marginal recall improvements.",
    keywords: [
      "improvements",
      "before",
      "change",
      "one",
      "metadata",
      "field",
      "time",
      "attribute",
      "keep",
      "log",
      "revisions",
      "timestamps",
      "test",
      "results",
      "share",
    ],
  },
  {
    id: "optimize-metadata-5",
    source: "Optimize Metadata",
    heading: "Production monitoring",
    content:
      "Once your connector is live:\n\n- Review tool-call analytics weekly. Spikes in “wrong tool” confirmations usually indicate metadata drift.\n- Capture user feedback and update descriptions to cover common misconceptions.\n- Schedule periodic prompt replays, especially after adding new tools or changing structured fields.\n\nTreat metadata as a living asset. The more intentional you are with wording and evaluation, the easier discovery and invocation become.",
    keywords: [
      "tool",
      "metadata",
      "once",
      "connector",
      "live",
      "review",
      "call",
      "analytics",
      "weekly",
      "spikes",
      "wrong",
      "confirmations",
      "usually",
      "indicate",
      "drift",
    ],
  },
  {
    id: "quickstart-0",
    source: "Quickstart",
    heading: "Introduction",
    content:
      "The Apps SDK relies on the [Model Context Protocol (MCP)](/apps-sdk/concepts/mcp-server) to expose your app to ChatGPT. To build an app for ChatGPT with the Apps SDK, you will need two things:\n\n1. A web component built with the framework of your choice – you are free to build your app as you see fit, that will be rendered in an iframe in the ChatGPT interface.\n2. A Model Context Protocol (MCP) server that will be used to expose your app and define your app's capabilities (tools) to ChatGPT.\n\nIn this quickstart, we'll build a simple to-do list app, contained in a single HTML file that keeps the markup, CSS, and JavaScript together.\n\nTo see more advanced examples using React, see the [examples repository on GitHub](https://github.com/openai/openai-apps-sdk-examples).",
    keywords: [
      "app",
      "apps",
      "sdk",
      "chatgpt",
      "mcp",
      "build",
      "examples",
      "model",
      "context",
      "protocol",
      "server",
      "expose",
      "github",
      "openai",
      "relies",
    ],
  },
  {
    id: "quickstart-1",
    source: "Quickstart",
    heading: "Build a web component",
    content:
      'Let\'s start by creating a file called `public/todo-widget.html` in a new directory that will be the UI rendered by the Apps SDK in ChatGPT.\nThis file will contain the web component that will be rendered in the ChatGPT interface.\n\nAdd the following content:\n\n```html\n<!DOCTYPE html>\n<html lang="en">\n  <head>\n    <meta charset="utf-8" />\n    <title>Todo list</title>\n    <style>\n      :root {\n        color: #0b0b0f;\n        font-family:\n          "Inter",\n          system-ui,\n          -apple-system,\n          sans-serif;\n      }\n\n      html,\n      body {\n        width: 100%;\n        min-height: 100%;\n        box-sizing: border-box;\n      }\n\n      body {\n        margin: 0;\n        padding: 16px;\n        background: #f6f8fb;\n      }\n\n      main {\n        width: 100%;\n        max-width: 360px;\n        min-height: 260px;\n        margin: 0 auto;\n        background: #fff;\n        border-radius: 16px;\n        padding: 20px;\n        box-shadow: 0 12px 24px rgba(15, 23, 42, 0.08);\n      }\n\n      h2 {\n        margin: 0 0 16px;\n        font-size: 1.25rem;\n      }\n\n      form {\n        display: flex;\n        gap: 8px;\n        margin-bottom: 16px;\n      }\n\n      form input {\n        flex: 1;\n        padding: 10px 12px;\n        border-radius: 10px;\n        border: 1px solid #cad3e0;\n        font-size: 0.95rem;\n      }\n\n      form button {\n        border: none;\n        border-radius: 10px;\n        background: #111bf5;\n        color: white;\n        font-weight: 600;\n        padding: 0 16px;\n        cursor: pointer;\n      }\n\n      input[type="checkbox"] {\n        accent-color: #111bf5;\n      }\n\n      ul {\n        list-style: none;\n        padding: 0;\n        margin: 0;\n        display: flex;\n        flex-direction: column;\n        gap: 8px;\n      }\n\n      li {\n        background: #f2f4fb;\n        border-radius: 12px;\n        padding: 10px 14px;\n        display: flex;\n        align-items: center;\n        gap: 10px;\n      }\n\n      li span {\n        flex: 1;\n      }\n\n      li[data-completed="true"] span {\n        text-decoration: line-through;\n        color: #6c768a;\n      }\n    </style>\n  </head>\n  <body>\n    <main>\n      <h2>Todo list</h2>\n      <form id="add-form" autocomplete="off">\n        <input id="todo-input" name="title" placeholder="Add a task" />\n        <button type="submit">Add</button>\n      </form>\n      <ul id="todo-list"></ul>\n    </main>\n\n    <script type="module">\n      const listEl = document.querySelector("#todo-list");\n      const formEl = document.querySelector("#add-form");\n      const inputEl = document.querySelector("#todo-input");\n\n      let tasks = [...(window.openai?.toolOutput?.tasks ?? [])];\n\n      const render = () => {\n        listEl.innerHTML = "";\n        tasks.forEach((task) => {\n          const li = document.createElement("li");\n          li.dataset.id = task.id;\n          li.dataset.completed = String(Boolean(task.completed));\n\n          const label = document.createElement("label");\n          label.style.display = "flex";\n          label.style.alignItems = "center";\n          label.style.gap = "10px";\n\n          const checkbox = document.createElement("input");\n          checkbox.type = "checkbox";\n          checkbox.checked = Boolean(task.completed);\n\n          const span = document.createElement("span");\n          span.textContent = task.title;\n\n          label.appendChild(checkbox);\n          label.appendChild(span);\n          li.appendChild(label);\n          listEl.appendChild(li);\n        });\n      };\n\n      const updateFromResponse = (response) => {\n        if (response?.structuredContent?.tasks) {\n          tasks = response.structuredContent.tasks;\n          render();\n        }\n      };\n\n      const handleSetGlobals = (event) => {\n        const globals = event.detail?.globals;\n        if (!globals?.toolOutput?.tasks) return;\n        tasks = globals.toolOutput.tasks;\n        render();\n      };\n\n      window.addEventListener("openai:set_globals", handleSetGlobals, {\n        passive: true,\n      });\n\n      const mutateTasksLocally = (name, payload) => {\n        if (name === "add_todo") {\n          tasks = [\n            ...tasks,\n            { id: crypto.randomUUID(), title: payload.title, completed: false },\n          ];\n        }\n\n        if (name === "complete_todo") {\n          tasks = tasks.map((task) =>\n            task.id === payload.id ? { ...task, completed: true } : task,\n          );\n        }\n\n        if (name === "set_completed") {\n          tasks = tasks.map((task) =>\n            task.id === payload.id\n              ? { ...task, completed: payload.completed }\n              : task,\n          );\n        }\n\n        render();\n      };\n\n      const callTodoTool = async (name, payload) => {\n        if (window.openai?.callTool) {\n          const response = await window.openai.callTool(name, payload);\n          updateFromResponse(response);\n          return;\n        }\n\n        mutateTasksLocally(name, payload);\n      };\n\n      formEl.addEventListener("submit", async (event) => {\n        event.preventDefault();\n        const title = inputEl.value.trim();\n        if (!title) return;\n        await callTodoTool("add_todo", { title });\n        inputEl.value = "";\n      });\n\n      listEl.addEventListener("change", async (event) => {\n        const checkbox = event.target;\n        if (!checkbox.matches(\'input[type="checkbox"]\')) return;\n        const id = checkbox.closest("li")?.dataset.id;\n        if (!id) return;\n\n        if (!checkbox.checked) {\n          if (window.openai?.callTool) {\n            checkbox.checked = true;\n            return;\n          }\n\n          mutateTasksLocally("set_completed", { id, completed: false });\n          return;\n        }\n\n        await callTodoTool("complete_todo", { id });\n      });\n\n      render();\n    </script>\n  </body>\n</html>\n```\n\n### Using the Apps SDK in your web component\n\n`window.openai` is the bridge between your frontend and ChatGPT.\n\nWhen ChatGPT loads the iframe, it injects the latest tool response into `window.openai.toolOutput`, which is an object specific to the Apps SDK.\nSubsequent calls to `window.openai.callTool` return fresh structured content so the UI stays in sync.',
    keywords: [
      "const",
      "tasks",
      "task",
      "checkbox",
      "title",
      "completed",
      "name",
      "window",
      "openai",
      "label",
      "return",
      "payload",
      "todo",
      "border",
      "form",
    ],
  },
  {
    id: "quickstart-2",
    source: "Quickstart",
    heading: "Build an MCP server",
    content:
      'Install the official Python or Node MCP SDK to create a server and expose a `/mcp` endpoint.\n\nIn this quickstart, we\'ll use the [Node SDK](https://github.com/modelcontextprotocol/typescript-sdk).\n\nIf you\'re using Python, refer to our [examples repository on GitHub](https://github.com/openai/openai-apps-sdk-examples) to see an example MCP server with the Python SDK.\n\nInstall the Node SDK and Zod with:\n\n```bash\nnpm install @modelcontextprotocol/sdk zod\n```\n\n### MCP server with Apps SDK resources\n\nRegister a resource for your component bundle and the tools the model can call (e.g. `add_todo` and `complete_todo`) so ChatGPT can drive the UI.\n\nCreate a file named `server.js` and paste the following example that uses the Node SDK:\n\n```js\nconst todoHtml = readFileSync("public/todo-widget.html", "utf8");\n\nconst addTodoInputSchema = {\n  title: z.string().min(1),\n};\n\nconst completeTodoInputSchema = {\n  id: z.string().min(1),\n};\n\nlet todos = [];\nlet nextId = 1;\n\nconst replyWithTodos = (message) => ({\n  content: message ? [{ type: "text", text: message }] : [],\n  structuredContent: { tasks: todos },\n});\n\nfunction createTodoServer() {\n  const server = new McpServer({ name: "todo-app", version: "0.1.0" });\n\n  server.registerResource(\n    "todo-widget",\n    "ui://widget/todo.html",\n    {},\n    async () => ({\n      contents: [\n        {\n          uri: "ui://widget/todo.html",\n          mimeType: "text/html+skybridge",\n          text: todoHtml,\n          _meta: { "openai/widgetPrefersBorder": true },\n        },\n      ],\n    }),\n  );\n\n  server.registerTool(\n    "add_todo",\n    {\n      title: "Add todo",\n      description: "Creates a todo item with the given title.",\n      inputSchema: addTodoInputSchema,\n      _meta: {\n        "openai/outputTemplate": "ui://widget/todo.html",\n        "openai/toolInvocation/invoking": "Adding todo",\n        "openai/toolInvocation/invoked": "Added todo",\n      },\n    },\n    async (args) => {\n      const title = args?.title?.trim?.() ?? "";\n      if (!title) return replyWithTodos("Missing title.");\n      const todo = { id: `todo-${nextId++}`, title, completed: false };\n      todos = [...todos, todo];\n      return replyWithTodos(`Added "${todo.title}".`);\n    },\n  );\n\n  server.registerTool(\n    "complete_todo",\n    {\n      title: "Complete todo",\n      description: "Marks a todo as done by id.",\n      inputSchema: completeTodoInputSchema,\n      _meta: {\n        "openai/outputTemplate": "ui://widget/todo.html",\n        "openai/toolInvocation/invoking": "Completing todo",\n        "openai/toolInvocation/invoked": "Completed todo",\n      },\n    },\n    async (args) => {\n      const id = args?.id;\n      if (!id) return replyWithTodos("Missing todo id.");\n      const todo = todos.find((task) => task.id === id);\n      if (!todo) {\n        return replyWithTodos(`Todo ${id} was not found.`);\n      }\n\n      todos = todos.map((task) =>\n        task.id === id ? { ...task, completed: true } : task,\n      );\n\n      return replyWithTodos(`Completed "${todo.title}".`);\n    },\n  );\n\n  return server;\n}\n\nconst port = Number(process.env.PORT ?? 8787);\nconst MCP_PATH = "/mcp";\n\nconst httpServer = createServer(async (req, res) => {\n  if (!req.url) {\n    res.writeHead(400).end("Missing URL");\n    return;\n  }\n\n  const url = new URL(req.url, `http://${req.headers.host ?? "localhost"}`);\n\n  if (req.method === "OPTIONS" && url.pathname === MCP_PATH) {\n    res.writeHead(204, {\n      "Access-Control-Allow-Origin": "*",\n      "Access-Control-Allow-Methods": "POST, GET, OPTIONS",\n      "Access-Control-Allow-Headers": "content-type, mcp-session-id",\n      "Access-Control-Expose-Headers": "Mcp-Session-Id",\n    });\n    res.end();\n    return;\n  }\n\n  if (req.method === "GET" && url.pathname === "/") {\n    res.writeHead(200, { "content-type": "text/plain" }).end("Todo MCP server");\n    return;\n  }\n\n  const MCP_METHODS = new Set(["POST", "GET", "DELETE"]);\n  if (url.pathname === MCP_PATH && req.method && MCP_METHODS.has(req.method)) {\n    res.setHeader("Access-Control-Allow-Origin", "*");\n    res.setHeader("Access-Control-Expose-Headers", "Mcp-Session-Id");\n\n    const server = createTodoServer();\n    const transport = new StreamableHTTPServerTransport({\n      sessionIdGenerator: undefined, // stateless mode\n      enableJsonResponse: true,\n    });\n\n    res.on("close", () => {\n      transport.close();\n      server.close();\n    });\n\n    try {\n      await server.connect(transport);\n      await transport.handleRequest(req, res);\n    } catch (error) {\n      console.error("Error handling MCP request:", error);\n      if (!res.headersSent) {\n        res.writeHead(500).end("Internal server error");\n      }\n    }\n    return;\n  }\n\n  res.writeHead(404).end("Not Found");\n});\n\nhttpServer.listen(port, () => {\n  console.log(\n    `Todo MCP server listening on http://localhost:${port}${MCP_PATH}`,\n  );\n});\n```\n\nThis snippet also responds to `GET /` for health checks, handles CORS preflight for `/mcp` and nested routes like `/mcp/actions`, and returns `404 Not Found` for OAuth discovery routes you are not using yet. That keeps ChatGPT’s connector wizard from surfacing 502 errors while you iterate without authentication.',
    keywords: [
      "todo",
      "const",
      "server",
      "mcp",
      "res",
      "title",
      "return",
      "sdk",
      "openai",
      "req",
      "url",
      "todos",
      "widget",
      "html",
      "replywithtodos",
    ],
  },
  {
    id: "quickstart-3",
    source: "Quickstart",
    heading: "Run locally",
    content:
      'If you\'re using a web framework like React, build your component into static assets so the HTML template can inline them.\nUsually, you can run a build command such as `npm run build` to produce a `dist` directory with your compiled assets.\n\nIn this quickstart, since we\'re using vanilla HTML, no build step is required.\n\nStart the MCP server on `http://localhost:<port>/mcp` from the directory that contains `server.js` (or `server.ts`).\n\nMake sure you have `"type": "module"` in your `package.json` file:\n\n```json\n{\n  "type": "module",\n  "dependencies": {\n    "@modelcontextprotocol/sdk": "^1.20.2",\n    "zod": "^3.25.76"\n  }\n}\n```\n\nThen run the server with the following command:\n\n```bash\nnode server.js\n```\n\nThe server should print `Todo MCP server listening on http://localhost:8787/mcp` once it is ready.\n\n### Test with MCP Inspector\n\nYou can use the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) to test your server locally.\n\n```bash\nnpx @modelcontextprotocol/inspector@latest http://localhost:8787/mcp\n```\n\nThis will open a browser window with the MCP Inspector interface. You can use this to test your server and see the tool responses.\n\n![MCP Inspector](/images/apps-sdk/mcp_inspector.png)\n\n### Expose your server to the public internet\n\nFor ChatGPT to access your server during development, you need to expose it to the public internet. You can use a tool such as [ngrok](https://ngrok.com/) to open a tunnel to your local server.\n\n```bash\nngrok http <port>\n```\n\nThis will give you a public URL like `https://<subdomain>.ngrok.app` that you can use to access your server from ChatGPT.\n\nWhen you add you connector, provide the public URL with the `/mcp` path (e.g. `https://<subdomain>.ngrok.app/mcp`).',
    keywords: [
      "server",
      "mcp",
      "inspector",
      "ngrok",
      "build",
      "http",
      "https",
      "public",
      "run",
      "localhost",
      "modelcontextprotocol",
      "bash",
      "test",
      "like",
      "assets",
    ],
  },
  {
    id: "quickstart-4",
    source: "Quickstart",
    heading: "Add your app to ChatGPT",
    content:
      'Once you have your MCP server and web component working locally, you can add your app to ChatGPT with the following steps:\n\n1. Enable [developer mode](https://platform.openai.com/docs/guides/developer-mode) under **Settings → Apps & Connectors → Advanced settings** in ChatGPT.\n2. Click the **Create** button to add a connector under **Settings → Connectors** and paste the HTTPS + `/mcp` URL from your tunnel or deployment (e.g. `https://<subdomain>.ngrok.app/mcp`).\n3. Name the connector, provide a short description and click **Create**.\n\n<div style={{ width: "50%", margin: "0 auto", display: "block" }}>\n  <img\n    src="/images/apps-sdk/new_connector.jpg"\n    alt="Add your connector to ChatGPT"\n  />\n</div>\n\n4. Open a new chat, add your connector from the **More** menu (accessible after clicking the **+** button), and prompt the model (e.g., “Add a new task to read my book”). ChatGPT will stream tool payloads so you can confirm inputs and outputs.\n\n![Add your connector to a conversation](/images/apps-sdk/developer_mode_more.jpg)',
    keywords: [
      "add",
      "connector",
      "chatgpt",
      "mcp",
      "https",
      "settings",
      "apps",
      "app",
      "developer",
      "mode",
      "under",
      "connectors",
      "click",
      "create",
      "button",
    ],
  },
  {
    id: "quickstart-5",
    source: "Quickstart",
    heading: "Next steps",
    content:
      "From there, you can iterate on the UI/UX, prompts, tool metadata, and the overall experience.\n\nRefresh the connector after each change to the MCP server (tools, metadata,\netc.) You can do this by clicking the **Refresh** button in **Settings →\nConnectors** after selecting your connector.\n\nRead our [ChatGPT app review guidelines](/apps-sdk/app-developer-guidelines) to learn more about the best practices for building apps for ChatGPT, and make sure you [research your use case](/apps-sdk/plan/use-case) and [read our design guidelines](/apps-sdk/concepts/design-guidelines) before building.\n\nOnce you understand the basics, you can leverage the Apps SDK to [build a ChatGPT UI](/apps-sdk/build/chatgpt-ui) using the Apps SDK primitives, [authenticate users](/apps-sdk/build/auth) if needed, and [persist state](/apps-sdk/build/storage).",
    keywords: [
      "apps",
      "sdk",
      "chatgpt",
      "guidelines",
      "build",
      "metadata",
      "refresh",
      "connector",
      "after",
      "read",
      "app",
      "building",
      "case",
      "design",
      "there",
    ],
  },
  {
    id: "reference-0",
    source: "Reference",
    heading: "`window.openai` component bridge",
    content: "See [build a ChatGPT UI](/apps-sdk/build/chatgpt-ui).",
    keywords: ["build", "chatgpt", "apps", "sdk"],
  },
  {
    id: "reference-1",
    source: "Reference",
    heading: "Tool descriptor parameters",
    content:
      'Need more background on these fields? Check the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced).\n\nBy default, a tool description should include the fields listed [here](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#tool).\n\n### `_meta` fields on tool descriptor\n\nWe have also require the following `_meta` fields on the tool descriptor:\n\n| Key                                       |    Placement    | Type         | Limits                          | Purpose                                                               |\n| ----------------------------------------- | :-------------: | ------------ | ------------------------------- | --------------------------------------------------------------------- |\n| `_meta["securitySchemes"]`                | Tool descriptor | array        | —                               | Back-compat mirror for clients that only read `_meta`.                |\n| `_meta["openai/outputTemplate"]`          | Tool descriptor | string (URI) | —                               | Resource URI for component HTML template (`text/html+skybridge`).     |\n| `_meta["openai/widgetAccessible"]`        | Tool descriptor | boolean      | default `false`                 | Allow component→tool calls through the client bridge.                 |\n| `_meta["openai/visibility"]`              | Tool descriptor | string       | `public` (default) or `private` | Hide a tool from the model while keeping it callable from the widget. |\n| `_meta["openai/toolInvocation/invoking"]` | Tool descriptor | string       | ≤ 64 chars                      | Short status text while the tool runs.                                |\n| `_meta["openai/toolInvocation/invoked"]`  | Tool descriptor | string       | ≤ 64 chars                      | Short status text after the tool completes.                           |\n\nExample:\n\n```ts\nserver.registerTool(\n  "search",\n  {\n    title: "Public Search",\n    description: "Search public documents.",\n    inputSchema: {\n      type: "object",\n      properties: { q: { type: "string" } },\n      required: ["q"],\n    },\n    securitySchemes: [\n      { type: "noauth" },\n      { type: "oauth2", scopes: ["search.read"] },\n    ],\n    _meta: {\n      securitySchemes: [\n        { type: "noauth" },\n        { type: "oauth2", scopes: ["search.read"] },\n      ],\n      "openai/outputTemplate": "ui://widget/story.html",\n      "openai/toolInvocation/invoking": "Searching…",\n      "openai/toolInvocation/invoked": "Results ready",\n    },\n  },\n  async ({ q }) => performSearch(q),\n);\n```\n\n### Annotations\n\nTo label a tool as "read-only", please use the following [annotation](https://modelcontextprotocol.io/specification/2025-06-18/server/resources#annotations) on the tool descriptor:\n\n| Key               | Type    | Required | Notes                                                                                                                                                           |\n| ----------------- | ------- | :------: | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `readOnlyHint`    | boolean | Optional | Signal that the tool is read-only. ChatGPT can skip “Are you sure?” prompts when this is `true`.                                                                |\n| `destructiveHint` | boolean | Optional | Declare that the tool may delete or overwrite user data so ChatGPT knows to elicit explicit approval first.                                                     |\n| `openWorldHint`   | boolean | Optional | Declare that the tool publishes content or reaches outside the current user’s account, prompting the client to summarize the impact before asking for approval. |\n\nThese hints only influence how ChatGPT frames the tool call to the user; servers must still enforce their own authorization logic.\n\nExample:\n\n```ts\nserver.registerTool(\n  "list_saved_recipes",\n  {\n    title: "List saved recipes",\n    description: "Returns the user’s saved recipes without modifying them.",\n    inputSchema: {\n      type: "object",\n      properties: {},\n      additionalProperties: false,\n    },\n    annotations: { readOnlyHint: true },\n  },\n  async () => fetchSavedRecipes(),\n);\n```\n\nNeed more background on these fields? Check the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced).',
    keywords: [
      "tool",
      "_meta",
      "descriptor",
      "type",
      "server",
      "openai",
      "fields",
      "read",
      "string",
      "search",
      "advanced",
      "mcp",
      "only",
      "boolean",
      "toolinvocation",
    ],
  },
  {
    id: "reference-2",
    source: "Reference",
    heading: "Component resource `_meta` fields",
    content:
      'Additional detail on these resource settings lives in the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced).\n\nSet these keys on the resource template that serves your component (`registerResource`). They help ChatGPT describe and frame the rendered iframe without leaking metadata to other clients.\n\n| Key                                   |     Placement     | Type            | Purpose                                                                                                        |\n| ------------------------------------- | :---------------: | --------------- | -------------------------------------------------------------------------------------------------------------- |\n| `_meta["openai/widgetDescription"]`   | Resource contents | string          | Human-readable summary surfaced to the model when the component loads, reducing redundant assistant narration. |\n| `_meta["openai/widgetPrefersBorder"]` | Resource contents | boolean         | Hint that the component should render inside a bordered card when supported.                                   |\n| `_meta["openai/widgetCSP"]`           | Resource contents | object          | Define `connect_domains` and `resource_domains` arrays for the component’s CSP snapshot.                       |\n| `_meta["openai/widgetDomain"]`        | Resource contents | string (origin) | Optional dedicated subdomain for hosted components (defaults to `https://web-sandbox.oaiusercontent.com`).     |',
    keywords: [
      "resource",
      "component",
      "_meta",
      "openai",
      "contents",
      "advanced",
      "mcp",
      "server",
      "string",
      "additional",
      "detail",
      "settings",
      "lives",
      "section",
      "guide",
    ],
  },
  {
    id: "reference-3",
    source: "Reference",
    heading: "Tool results",
    content:
      'The [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced) provides more guidance on shaping these response fields.\n\nTool results can contain the following [fields](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#tool-result). Notably:\n\n| Key                 | Type                  | Required | Notes                                                                                           |\n| ------------------- | --------------------- | -------- | ----------------------------------------------------------------------------------------------- |\n| `structuredContent` | object                | Optional | Surfaced to the model and the component. Must match the declared `outputSchema`, when provided. |\n| `content`           | string or `Content[]` | Optional | Surfaced to the model and the component.                                                        |\n| `_meta`             | object                | Optional | Delivered only to the component. Hidden from the model.                                         |\n\nOnly `structuredContent` and `content` appear in the conversation transcript. `_meta` is forwarded to the component so you can hydrate UI without exposing the data to the model.\n\nExample:\n\n```ts\nserver.registerTool(\n  "get_zoo_animals",\n  {\n    title: "get_zoo_animals",\n    inputSchema: { count: z.number().int().min(1).max(20).optional() },\n    _meta: { "openai/outputTemplate": "ui://widget/widget.html" },\n  },\n  async ({ count = 10 }) => {\n    const animals = generateZooAnimals(count);\n\n    return {\n      structuredContent: { animals },\n      content: [{ type: "text", text: `Here are ${animals.length} animals.` }],\n      _meta: {\n        allAnimalsById: Object.fromEntries(\n          animals.map((animal) => [animal.id, animal]),\n        ),\n      },\n    };\n  },\n);\n```\n\n### Error tool result\n\nTo return an error on the tool result, use the following `_meta` key:\n\n| Key                             | Purpose      | Type               | Notes                                                    |\n| ------------------------------- | ------------ | ------------------ | -------------------------------------------------------- |\n| `_meta["mcp/www_authenticate"]` | Error result | string or string[] | RFC 7235 `WWW-Authenticate` challenges to trigger OAuth. |',
    keywords: [
      "_meta",
      "animals",
      "server",
      "tool",
      "result",
      "optional",
      "model",
      "component",
      "content",
      "mcp",
      "key",
      "type",
      "structuredcontent",
      "object",
      "string",
    ],
  },
  {
    id: "reference-4",
    source: "Reference",
    heading: "`_meta` fields the client provides",
    content:
      'See the [Advanced section of the MCP server guide](/apps-sdk/build/mcp-server#advanced) for broader context on these client-supplied hints.\n\n| Key                            | When provided           | Type            | Purpose                                                                                     |\n| ------------------------------ | ----------------------- | --------------- | ------------------------------------------------------------------------------------------- |\n| `_meta["openai/locale"]`       | Initialize + tool calls | string (BCP 47) | Requested locale (older clients may send `_meta["webplus/i18n"]`).                          |\n| `_meta["openai/userAgent"]`    | Tool calls              | string          | User agent hint for analytics or formatting.                                                |\n| `_meta["openai/userLocation"]` | Tool calls              | object          | Coarse location hint (`city`, `region`, `country`, `timezone`, `longitude`, `latitude`).    |\n| `_meta["openai/subject"]`      | Tool calls              | string          | Anonymized user id sent to MCP servers for the purposes of rate limiting and identification |\n\nOperation-phase `_meta["openai/userAgent"]` and `_meta["openai/userLocation"]` are hints only; servers should never rely on them for authorization decisions and must tolerate their absence.\n\nExample:\n\n```ts\nserver.registerTool(\n  "recommend_cafe",\n  {\n    title: "Recommend a cafe",\n    inputSchema: { type: "object" },\n  },\n  async (_args, { _meta }) => {\n    const locale = _meta?.["openai/locale"] ?? "en";\n    const location = _meta?.["openai/userLocation"]?.city;\n\n    return {\n      content: [{ type: "text", text: formatIntro(locale, location) }],\n      structuredContent: await findNearbyCafes(location),\n    };\n  },\n);\n```',
    keywords: [
      "_meta",
      "openai",
      "locale",
      "tool",
      "calls",
      "location",
      "mcp",
      "server",
      "type",
      "string",
      "userlocation",
      "advanced",
      "hints",
      "useragent",
      "user",
    ],
  },
  {
    id: "security-and-privacy-0",
    source: "Security and Privacy",
    heading: "Principles",
    content:
      "Apps SDK gives your code access to user data, third-party APIs, and write actions. Treat every connector as production software:\n\n- **Least privilege** – only request the scopes, storage access, and network permissions you need.\n- **Explicit user consent** – make sure users understand when they are linking accounts or granting write access. Lean on ChatGPT’s confirmation prompts for potentially destructive actions.\n- **Defense in depth** – assume prompt injection and malicious inputs will reach your server. Validate everything and keep audit logs.",
    keywords: [
      "access",
      "user",
      "write",
      "actions",
      "apps",
      "sdk",
      "gives",
      "code",
      "data",
      "third",
      "party",
      "apis",
      "treat",
      "every",
      "connector",
    ],
  },
  {
    id: "security-and-privacy-1",
    source: "Security and Privacy",
    heading: "Data handling",
    content:
      "- **Structured content** – include only the data required for the current prompt. Avoid embedding secrets or tokens in component props.\n- **Storage** – decide how long you keep user data and publish a retention policy. Respect deletion requests promptly.\n- **Logging** – redact PII before writing to logs. Store correlation IDs for debugging but avoid storing raw prompt text unless necessary.",
    keywords: [
      "data",
      "prompt",
      "avoid",
      "structured",
      "content",
      "include",
      "only",
      "required",
      "current",
      "embedding",
      "secrets",
      "tokens",
      "component",
      "props",
      "storage",
    ],
  },
  {
    id: "security-and-privacy-2",
    source: "Security and Privacy",
    heading: "Prompt injection and write actions",
    content:
      "Developer mode enables full MCP access, including write tools. Mitigate risk by:\n\n- Reviewing tool descriptions regularly to discourage misuse (“Do not use to delete records”).\n- Validating all inputs server-side even if the model provided them.\n- Requiring human confirmation for irreversible operations.\n\nShare your best prompts for testing injections with your QA team so they can probe weak spots early.",
    keywords: [
      "developer",
      "mode",
      "enables",
      "full",
      "mcp",
      "access",
      "including",
      "write",
      "tools",
      "mitigate",
      "risk",
      "reviewing",
      "tool",
      "descriptions",
      "regularly",
    ],
  },
  {
    id: "security-and-privacy-3",
    source: "Security and Privacy",
    heading: "Network access",
    content:
      "Widgets run inside a sandboxed iframe with a strict Content Security Policy. They cannot access privileged browser APIs such as `window.alert`, `window.prompt`, `window.confirm`, or `navigator.clipboard`. Standard `fetch` requests are allowed only when they comply with the CSP. Subframes (iframes) are blocked by default and only allowed when you explicitly set `frame_domains` in `openai/widgetCSP`, which is reserved for high-trust, narrowly scoped use cases. Work with your OpenAI partner if you need specific domains allow-listed.\n\nServer-side code has no network restrictions beyond what your hosting environment enforces. Follow normal best practices for outbound calls (TLS verification, retries, timeouts).",
    keywords: [
      "window",
      "allowed",
      "only",
      "openai",
      "widgets",
      "run",
      "inside",
      "sandboxed",
      "iframe",
      "strict",
      "content",
      "security",
      "policy",
      "cannot",
      "access",
    ],
  },
  {
    id: "security-and-privacy-4",
    source: "Security and Privacy",
    heading: "Authentication & authorization",
    content:
      "- Use OAuth 2.1 flows that include PKCE and dynamic client registration when integrating external accounts.\n- Verify and enforce scopes on every tool call. Reject expired or malformed tokens with `401` responses.\n- For built-in identity, avoid storing long-lived secrets; use the provided auth context instead.",
    keywords: [
      "oauth",
      "flows",
      "include",
      "pkce",
      "dynamic",
      "client",
      "registration",
      "integrating",
      "external",
      "accounts",
      "verify",
      "enforce",
      "scopes",
      "every",
      "tool",
    ],
  },
  {
    id: "security-and-privacy-5",
    source: "Security and Privacy",
    heading: "Operational readiness",
    content:
      "- Run security reviews before launch, especially if you handle regulated data.\n- Monitor for anomalous traffic patterns and set up alerts for repeated errors or failed auth attempts.\n- Keep third-party dependencies (React, SDKs, build tooling) patched to mitigate supply chain risks.\n\nSecurity and privacy are foundational to user trust. Bake them into your planning, implementation, and deployment workflows rather than treating them as an afterthought.",
    keywords: [
      "security",
      "them",
      "run",
      "reviews",
      "before",
      "launch",
      "especially",
      "handle",
      "regulated",
      "data",
      "monitor",
      "anomalous",
      "traffic",
      "patterns",
      "set",
    ],
  },
  {
    id: "submit-your-app-0",
    source: "Submit your app",
    heading: "App submission overview",
    content:
      "Once you have built and [tested your app](/apps-sdk/deploy/testing) in Developer Mode, you can submit your app to the ChatGPT Apps Directory to make it publicly available.\n\nOnly submit your app if you intend for it to be accessible to all users. Submitting an app initiates a review process, and you’ll be notified of its status as it moves through review.\n\nBefore submitting, make sure your app complies with our [App Submission\nGuidelines](/apps-sdk/app-submission-guidelines).\n\nIf your app is approved, it can be listed in the ChatGPT Apps Directory.\nInitially, users will be able to discover your app in one of the following ways:\n\n- By clicking a direct link to your app in the directory\n- By searching for your app by name\n\nApps that demonstrate strong real-world utility and high user satisfaction may be eligible for enhanced distribution opportunities—such as directory placement or proactive suggestions.",
    keywords: [
      "app",
      "apps",
      "directory",
      "sdk",
      "submit",
      "chatgpt",
      "make",
      "users",
      "submitting",
      "review",
      "submission",
      "guidelines",
      "once",
      "built",
      "tested",
    ],
  },
  {
    id: "submit-your-app-1",
    source: "Submit your app",
    heading: "Pre-requisites",
    content:
      "### Organization verification\n\nYour organization needs to be verified on the OpenAI Platform to be able to submit an app.\n\nYou can complete individual or business verification in the [OpenAI Platform Dashboard general settings](https://platform.openai.com/settings/organization/general). Once you’ve verified the profile you plan to publish under, that identity will be available to pick during app submission.\n\n### Owner role\n\nYou must have the **Owner** role in an organization to complete verification and create and submit apps for review.\n\nIf you aren’t currently an Owner, your organization’s current owners will need to grant you this role to proceed.",
    keywords: [
      "organization",
      "verification",
      "openai",
      "platform",
      "owner",
      "role",
      "verified",
      "submit",
      "app",
      "complete",
      "general",
      "settings",
      "needs",
      "able",
      "individual",
    ],
  },
  {
    id: "submit-your-app-2",
    source: "Submit your app",
    heading: "Submission process",
    content:
      "If the pre-requisites are met, you can submit your app for review from the [OpenAI Platform Dashboard](http://platform.openai.com/apps-manage).\n\n### MCP server requirements\n\n- Your MCP server is hosted on a publicly accessible domain\n- You are not using a local or testing endpoint\n- You defined a [CSP](/apps-sdk/build/mcp-server#content-security-policy-csp) to allow the exact domains you fetch from (this is required to submit your app for security reasons)\n\n### Start the review process\n\nFrom the dashboard:\n\n1. Add your MCP server details (as well as OAuth metadata if OAuth is selected)\n2. Confirm that your app complies with OpenAI policies.\n3. Complete the required fields in the submission form and check all confirmation boxes.\n4. Click **Submit for review**.\n\nOnce submitted, your app will enter the review queue.\n\nWhile you can publish multiple, unique apps within a single Platform organization, each may only have one version in review at a time.",
    keywords: [
      "review",
      "app",
      "mcp",
      "server",
      "submit",
      "openai",
      "platform",
      "apps",
      "dashboard",
      "csp",
      "security",
      "required",
      "oauth",
      "pre",
      "requisites",
    ],
  },
  {
    id: "submit-your-app-3",
    source: "Submit your app",
    heading: "After Submission",
    content:
      "You can review the status of the review within the Dashboard and will receive an email notification informing you of any status changes.\n\n### Publish your app\n\nOnce your app is approved, you can publish it to the ChatGPT Apps Directory by clicking the **Publish** button in the Dashboard.\nThis will make your app discoverable by ChatGPT users.\n\n### Reviews and checks\n\nWe may perform automated scans or manual reviews to understand how your app works and whether it may conflict with our policies. If your app is rejected or removed, you will receive feedback and may have the opportunity to appeal.\n\n### Maintenance and removal\n\nApps that are inactive, unstable, or no longer compliant may be removed. We may reject or remove any app from our services at any time and for any reason without notice, such as for legal or security concerns or policy violations.\n\n### Re-submission for changes\n\nOnce your app is published, tool names, signatures, and descriptions are locked for safety. To add or update your app’s tools or metadata, you must resubmit the app for review. Once your resubmission is approved, you can publish the update which will replace the previous version of your app.",
    keywords: [
      "app",
      "any",
      "publish",
      "review",
      "once",
      "status",
      "dashboard",
      "receive",
      "changes",
      "approved",
      "chatgpt",
      "apps",
      "reviews",
      "removed",
      "update",
    ],
  },
  {
    id: "test-your-integration-0",
    source: "Test your integration",
    heading: "Goals",
    content:
      "Testing validates that your connector behaves predictably before you expose it to users. Focus on three areas: tool correctness, component UX, and discovery precision.",
    keywords: [
      "testing",
      "validates",
      "connector",
      "behaves",
      "predictably",
      "before",
      "expose",
      "users",
      "focus",
      "three",
      "areas",
      "tool",
      "correctness",
      "component",
      "discovery",
    ],
  },
  {
    id: "test-your-integration-1",
    source: "Test your integration",
    heading: "Unit test your tool handlers",
    content:
      "- Exercise each tool function directly with representative inputs. Verify schema validation, error handling, and edge cases (empty results, missing IDs).\n- Include automated tests for authentication flows if you issue tokens or require linking.\n- Keep test fixtures close to your MCP code so they stay up to date as schemas evolve.",
    keywords: [
      "exercise",
      "each",
      "tool",
      "function",
      "directly",
      "representative",
      "inputs",
      "verify",
      "schema",
      "validation",
      "error",
      "handling",
      "edge",
      "cases",
      "empty",
    ],
  },
  {
    id: "test-your-integration-2",
    source: "Test your integration",
    heading: "Use MCP Inspector during development",
    content:
      "The [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) is the fastest way to debug your server locally:\n\n1. Run your MCP server.\n2. Launch the inspector: `npx @modelcontextprotocol/inspector@latest`.\n3. Enter your server URL (for example `http://127.0.0.1:2091/mcp`).\n4. Click **List Tools** and **Call Tool** to inspect the raw requests and responses.\n\nInspector renders components inline and surfaces errors immediately. Capture screenshots for your launch review.",
    keywords: [
      "inspector",
      "mcp",
      "server",
      "modelcontextprotocol",
      "tools",
      "launch",
      "https",
      "docs",
      "fastest",
      "way",
      "debug",
      "locally",
      "run",
      "npx",
      "latest",
    ],
  },
  {
    id: "test-your-integration-3",
    source: "Test your integration",
    heading: "Validate in ChatGPT developer mode",
    content:
      "After your connector is reachable over HTTPS:\n\n- Link it in **Settings → Connectors → Developer mode**.\n- Toggle it on in a new conversation and run through your golden prompt set (direct, indirect, negative). Record when the model selects the right tool, what arguments it passed, and whether confirmation prompts appear as expected.\n- Test mobile layouts by invoking the connector in the ChatGPT iOS or Android apps.",
    keywords: [
      "connector",
      "after",
      "reachable",
      "over",
      "https",
      "link",
      "settings",
      "connectors",
      "developer",
      "mode",
      "toggle",
      "new",
      "conversation",
      "run",
      "through",
    ],
  },
  {
    id: "test-your-integration-4",
    source: "Test your integration",
    heading: "Connect via the API Playground",
    content:
      "If you need raw logs or want to test without the full ChatGPT UI, open the [API Playground](https://platform.openai.com/playground):\n\n1. Choose **Tools → Add → MCP Server**.\n2. Provide your HTTPS endpoint and connect.\n3. Issue test prompts and inspect the JSON request/response pairs in the right-hand panel.",
    keywords: [
      "test",
      "playground",
      "https",
      "need",
      "raw",
      "logs",
      "want",
      "without",
      "full",
      "chatgpt",
      "open",
      "api",
      "platform",
      "openai",
      "com",
    ],
  },
  {
    id: "test-your-integration-5",
    source: "Test your integration",
    heading: "Regression checklist before launch",
    content:
      "- Tool list matches your documentation and unused prototypes are removed.\n- Structured content matches the declared `outputSchema` for every tool.\n- Widgets render without console errors, inject their own styling, and restore state correctly.\n- OAuth or custom auth flows return valid tokens and reject invalid ones with meaningful messages.\n- Discovery behaves as expected across your golden prompts and does not trigger on negative prompts.\n\nCapture findings in a doc so you can compare results release over release. Consistent testing keeps your connector reliable as ChatGPT and your backend evolve.",
    keywords: [
      "tool",
      "matches",
      "prompts",
      "release",
      "list",
      "documentation",
      "unused",
      "prototypes",
      "removed",
      "structured",
      "content",
      "declared",
      "outputschema",
      "every",
      "widgets",
    ],
  },
  {
    id: "troubleshooting-0",
    source: "Troubleshooting",
    heading: "How to triage issues",
    content:
      "When something goes wrong—components failing to render, discovery missing prompts, auth loops—start by isolating which layer is responsible: server, component, or ChatGPT client. The checklist below covers the most common problems and how to resolve them.",
    keywords: [
      "something",
      "goes",
      "wrong",
      "components",
      "failing",
      "render",
      "discovery",
      "missing",
      "prompts",
      "auth",
      "loops",
      "start",
      "isolating",
      "layer",
      "responsible",
    ],
  },
  {
    id: "troubleshooting-1",
    source: "Troubleshooting",
    heading: "Server-side issues",
    content:
      '- **No tools listed** – confirm your server is running and that you are connecting to the `/mcp` endpoint. If you changed ports, update the connector URL and restart MCP Inspector.\n- **Structured content only, no component** – confirm the tool response sets `_meta["openai/outputTemplate"]` to a registered HTML resource with `mimeType: "text/html+skybridge"`, and that the resource loads without CSP errors.\n- **Schema mismatch errors** – ensure your Pydantic or TypeScript models match the schema advertised in `outputSchema`. Regenerate types after making changes.\n- **Slow responses** – components feel sluggish when tool calls take longer than a few hundred milliseconds. Profile backend calls and cache results when possible.',
    keywords: [
      "confirm",
      "mcp",
      "tool",
      "html",
      "resource",
      "errors",
      "schema",
      "calls",
      "tools",
      "listed",
      "server",
      "running",
      "connecting",
      "endpoint",
      "changed",
    ],
  },
  {
    id: "troubleshooting-2",
    source: "Troubleshooting",
    heading: "Widget issues",
    content:
      "- **Widget fails to load** – open the browser console (or MCP Inspector logs) for CSP violations or missing bundles. Make sure the HTML inlines your compiled JS and that all dependencies are bundled.\n- **Drag-and-drop or editing doesn’t persist** – verify you call `window.openai.setWidgetState` after each update and that you rehydrate from `window.openai.widgetState` on mount.\n- **Layout problems on mobile** – inspect `window.openai.displayMode` and `window.openai.maxHeight` to adjust layout. Avoid fixed heights or hover-only actions.",
    keywords: [
      "window",
      "openai",
      "layout",
      "widget",
      "fails",
      "load",
      "open",
      "browser",
      "console",
      "mcp",
      "inspector",
      "logs",
      "csp",
      "violations",
      "missing",
    ],
  },
  {
    id: "troubleshooting-3",
    source: "Troubleshooting",
    heading: "Discovery and entry-point issues",
    content:
      "- **Tool never triggers** – revisit your metadata. Rewrite descriptions with “Use this when…” phrasing, update starter prompts, and retest using your golden prompt set.\n- **Wrong tool selected** – add clarifying details to similar tools or specify disallowed scenarios in the description. Consider splitting large tools into smaller, purpose-built ones.\n- **Launcher ranking feels off** – refresh your directory metadata and ensure the app icon and descriptions match what users expect.",
    keywords: [
      "tool",
      "metadata",
      "descriptions",
      "tools",
      "never",
      "triggers",
      "revisit",
      "rewrite",
      "phrasing",
      "update",
      "starter",
      "prompts",
      "retest",
      "golden",
      "prompt",
    ],
  },
  {
    id: "troubleshooting-4",
    source: "Troubleshooting",
    heading: "Authentication problems",
    content:
      "- **401 errors** – include a `WWW-Authenticate` header in the error response so ChatGPT knows to start the OAuth flow again. Double-check issuer URLs and audience claims.\n- **Dynamic client registration fails** – confirm your authorization server exposes `registration_endpoint` and that newly created clients have at least one login connection enabled.",
    keywords: [
      "401",
      "errors",
      "include",
      "www",
      "authenticate",
      "header",
      "error",
      "response",
      "chatgpt",
      "knows",
      "start",
      "oauth",
      "flow",
      "again",
      "double",
    ],
  },
  {
    id: "troubleshooting-5",
    source: "Troubleshooting",
    heading: "Deployment problems",
    content:
      "- **Ngrok tunnel times out** – restart the tunnel and verify your local server is running before sharing the URL. For production, use a stable hosting provider with health checks.\n- **Streaming breaks behind proxies** – ensure your load balancer or CDN allows server-sent events or streaming HTTP responses without buffering.",
    keywords: [
      "tunnel",
      "server",
      "streaming",
      "ngrok",
      "times",
      "out",
      "restart",
      "verify",
      "local",
      "running",
      "before",
      "sharing",
      "url",
      "production",
      "stable",
    ],
  },
  {
    id: "troubleshooting-6",
    source: "Troubleshooting",
    heading: "When to escalate",
    content:
      "If you have validated the points above and the issue persists:\n\n1. Collect logs (server, component console, ChatGPT tool call transcript) and screenshots.\n2. Note the prompt you issued and any confirmation dialogs.\n3. Share the details with your OpenAI partner contact so they can reproduce the issue internally.\n\nA crisp troubleshooting log shortens turnaround time and keeps your connector reliable for users.",
    keywords: [
      "issue",
      "validated",
      "points",
      "above",
      "persists",
      "collect",
      "logs",
      "server",
      "component",
      "console",
      "chatgpt",
      "tool",
      "call",
      "transcript",
      "screenshots",
    ],
  },
  {
    id: "ui-guidelines-0",
    source: "UI Guidelines",
    heading: "Overview",
    content:
      "Apps are developer-built experiences that are available in ChatGPT. They extend what users can do without breaking the flow of conversation, appearing through lightweight cards, carousels, fullscreen views, and other display modes that integrate seamlessly into ChatGPT’s interface.\n\nBefore you start designing your app visually, make sure you have reviewed our\nrecommended [UX principles](/apps-sdk/concepts/ux-principles).\n\n![Example apps in the ChatGPT mobile interface](/images/apps-sdk/overview.png)",
    keywords: [
      "apps",
      "chatgpt",
      "interface",
      "principles",
      "sdk",
      "developer",
      "built",
      "experiences",
      "available",
      "extend",
      "users",
      "without",
      "breaking",
      "flow",
      "conversation",
    ],
  },
  {
    id: "ui-guidelines-1",
    source: "UI Guidelines",
    heading: "Design system",
    content:
      "To help you design high quality apps that feel native to ChatGPT, you can use the [Apps SDK UI](https://openai.github.io/apps-sdk-ui/) design system.\n\nIt provides styling foundations with Tailwind, CSS variable design tokens, and a library of well-crafted, accessible components.\n\nUsing the Apps SDK UI is not a requirement to build your app, but it will make building an app for ChatGPT faster and easier, in a way that is consistent with the ChatGPT design system.\n\nBefore diving into code, start designing with our [Figma component\nlibrary](https://www.figma.com/community/file/1560064615791108827/apps-in-chatgpt-components-templates)",
    keywords: [
      "apps",
      "design",
      "chatgpt",
      "sdk",
      "https",
      "system",
      "library",
      "components",
      "app",
      "figma",
      "help",
      "high",
      "quality",
      "feel",
      "native",
    ],
  },
  {
    id: "ui-guidelines-2",
    source: "UI Guidelines",
    heading: "Display modes",
    content:
      "Display modes are the surfaces developers use to create experiences for apps in ChatGPT. They allow partners to show content and actions that feel native to conversation. Each mode is designed for a specific type of interaction, from quick confirmations to immersive workflows.\n\nUsing these consistently helps experiences stay simple and predictable.\n\n### Inline\n\nThe inline display mode appears directly in the flow of the conversation. Inline surfaces currently always appear before the generated model response. Every app initially appears inline.\n\n![Examples of inline cards and carousels in ChatGPT](/images/apps-sdk/inline_display_mode.png)\n\n**Layout**\n\n- **Icon & tool call**: A label with the app name and icon.\n- **Inline display**: A lightweight display with app content embedded above the model response.\n- **Follow-up**: A short, model-generated response shown after the widget to suggest edits, next steps, or related actions. Avoid content that is redundant with the card.\n\n#### Inline card\n\nLightweight, single-purpose widgets embedded directly in conversation. They provide quick confirmations, simple actions, or visual aids.\n\n![Examples of inline cards](/images/apps-sdk/inline_cards.png)\n\n**When to use**\n\n- A single action or decision (for example, confirm a booking).\n- Small amounts of structured data (for example, a map, order summary, or quick status).\n- A fully self-contained widget or tool (e.g., an audio player or a score card).\n\n**Layout**\n\n![Diagram of inline cards](/images/apps-sdk/inline_card_layout.png)\n\n- **Title**: Include a title if your card is document-based or contains items with a parent element, like songs in a playlist.\n- **Expand**: Use to open a fullscreen display mode if the card contains rich media or interactivity like a map or an interactive diagram.\n- **Show more**: Use to disclose additional items if multiple results are presented in a list.\n- **Edit controls**: Provide inline support for app responses without overwhelming the conversation.\n- **Primary actions**: Limit to two actions, placed at bottom of card. Actions should perform either a conversation turn or a tool call.\n\n**Interaction**\n\n![Diagram of interaction patterns for inline cards](/images/apps-sdk/inline_card_interaction.png)\n\nCards support simple direct interaction.\n\n- **States**: Edits made are persisted.\n- **Simple direct edits**: If appropriate, inline editable text allows users to make quick edits without needing to prompt the model.\n- **Dynamic layout**: Card layout can expand its height to match its contents up to the height of the mobile viewport.\n\n**Rules of thumb**\n\n- **Limit primary actions per card**: Support up to two actions maximum, with one primary CTA and one optional secondary CTA.\n- **No deep navigation or multiple views within a card.** Cards should not contain multiple drill-ins, tabs, or deeper navigation. Consider splitting these into separate cards or tool actions.\n- **No nested scrolling**. Cards should auto-fit their content and prevent internal scrolling.\n- **No duplicative inputs**. Don’t replicate ChatGPT features in a card.\n\n![Examples of patterns to avoid in inline cards](/images/apps-sdk/inline_card_rules.png)\n\n#### Inline carousel\n\nA set of cards presented side-by-side, letting users quickly scan and choose from multiple options.\n\n![Example of inline carousel](/images/apps-sdk/inline_carousel.png)\n\n**When to use**\n\n- Presenting a small list of similar items (for example, restaurants, playlists, events).\n- Items have more visual content and metadata than will fit in simple rows.\n\n**Layout**\n\n![Diagram of inline carousel](/images/apps-sdk/inline_carousel_layout.png)\n\n- **Image**: Items should always include an image or visual.\n- **Title**: Carousel items should typically include a title to explain the content.\n- **Metadata**: Use metadata to show the most important and relevant information about the item in the context of the response. Avoid showing more than two lines of text.\n- **Badge**: Use the badge to show supporting context where appropriate.\n- **Actions**: Provide a single clear CTA per item whenever possible.\n\n**Rules of thumb**\n\n- Keep to **3–8 items per carousel** for scannability.\n- Reduce metadata to the most relevant details, with three lines max.\n- Each card may have a single, optional CTA (for example, “Book” or “Play”).\n- Use consistent visual hierarchy across cards.\n\n### Fullscreen\n\nImmersive experiences that expand beyond the inline card, giving users space for multi-step workflows or deeper exploration. The ChatGPT composer remains overlaid, allowing users to continue “talking to the app” through natural conversation in the context of the fullscreen view.\n\n![Example of fullscreen](/images/apps-sdk/fullscreen.png)\n\n**When to use**\n\n- Rich tasks that cannot be reduced to a single card (for example, an explorable map with pins, a rich editing canvas, or an interactive diagram).\n- Browsing detailed content (for example, real estate listings, menus).\n\n**Layout**\n\n![Diagram of fullscreen](/images/apps-sdk/fullscreen_layout.png)\n\n- **System close**: Closes the sheet or view.\n- **Fullscreen view**: Content area.\n- **Composer**: ChatGPT’s native composer, allowing the user to follow up in the context of the fullscreen view.\n\n**Interaction**\n\n![Interaction patterns for fullscreen](/images/apps-sdk/fullscreen_interaction_a.png)\n\n- **Chat sheet**: Maintain conversational context alongside the fullscreen surface.\n- **Thinking**: The composer input “shimmers” to show that a response is streaming.\n- **Response**: When the model completes its response, an ephemeral, truncated snippet displays above the composer. Tapping it opens the chat sheet.\n\n**Rules of thumb**\n\n- **Design your UX to work with the system composer**. The composer is always present in fullscreen, so make sure your experience supports conversational prompts that can trigger tool calls and feel natural for users.\n- **Use fullscreen to deepen engagement**, not to replicate your native app wholesale.\n\n### Picture-in-picture (PiP)\n\nA persistent floating window inside ChatGPT optimized for ongoing or live sessions like games or videos. PiP remains visible while the conversation continues, and it can update dynamically in response to user prompts.\n\n![Example of picture-in-picture](/images/apps-sdk/pip.png)\n\n**When to use**\n\n- **Activities that run in parallel with conversation**, such as a game, live collaboration, quiz, or learning session.\n- **Situations where the PiP widget can react to chat input**, for example continuing a game round or refreshing live data based on a user request.\n\n**Interaction**\n\n![Interaction patterns for picture-in-picture](/images/apps-sdk/fullscreen_interaction.png)\n\n- **Activated:** On scroll, the PiP window stays fixed to the top of the viewport\n- **Pinned:** The PiP remains fixed until the user dismisses it or the session ends.\n- **Session ends:** The PiP returns to an inline position and scrolls away.\n\n**Rules of thumb**\n\n- **Ensure the PiP state can update or respond** when users interact through the system composer.\n- **Close PiP automatically** when the session ends.\n- **Do not overload PiP with controls or static content** better suited for inline or fullscreen.",
    keywords: [
      "inline",
      "apps",
      "card",
      "fullscreen",
      "images",
      "sdk",
      "png",
      "cards",
      "actions",
      "example",
      "pip",
      "content",
      "conversation",
      "interaction",
      "response",
    ],
  },
  {
    id: "ui-guidelines-3",
    source: "UI Guidelines",
    heading: "Visual design guidelines",
    content:
      "A consistent look and feel helps partner-built tools feel like a natural part of the ChatGPT platform. Visual guidelines support clarity, usability, and accessibility, while still leaving room for brand expression in the right places.\n\nThese principles outline how to use color, type, spacing, and imagery in ways that preserve system clarity while giving partners space to differentiate their service.\n\n### Why this matters\n\nVisual and UX consistency helps improve the overall user experience of using apps in ChatGPT. By following these guidelines, partners can present their tools in a way that feels consistent to users and delivers value without distraction.\n\n### Color\n\nSystem-defined palettes help ensure actions and responses always feel consistent with the ChatGPT platform. Partners can add branding through accents, icons, or inline imagery, but should not redefine system colors.\n\n![Color palette](/images/apps-sdk/color.png)\n\n**Rules of thumb**\n\n- Use system colors for text, icons, and spatial elements like dividers.\n- Partner brand accents such as logos or icons should not override backgrounds or text colors.\n- Avoid custom gradients or patterns that break ChatGPT’s minimal look.\n- Use brand accent colors on primary buttons inside app display modes.\n\n![Example color usage](/images/apps-sdk/color_usage_1.png)\n\n_Use brand colors on accents and badges. Don't change text colors or other core component styles._\n\n![Example color usage](/images/apps-sdk/color_usage_2.png)\n\n_Don't apply colors to backgrounds in text areas._\n\n### Typography\n\nChatGPT uses platform-native system fonts (SF Pro on iOS, Roboto on Android) to ensure readability and accessibility across devices.\n\n![Typography](/images/apps-sdk/typography.png)\n\n**Rules of thumb**\n\n- Always inherit the system font stack, respecting system sizing rules for headings, body text, and captions.\n- Use partner styling such as bold, italic, or highlights only within content areas, not for structural UI.\n- Limit variation in font size as much as possible, preferring body and body-small sizes.\n\n![Example typography](/images/apps-sdk/typography_usage.png)\n\n_Don't use custom fonts, even in full screen modes. Use system font variables wherever possible._\n\n### Spacing & layout\n\nConsistent margins, padding, and alignment keep partner content scannable and predictable inside conversation.\n\n![Spacing & layout](/images/apps-sdk/spacing.png)\n\n**Rules of thumb**\n\n- Use system grid spacing for cards, collections, and inspector panels.\n- Keep padding consistent and avoid cramming or edge-to-edge text.\n- Respect system specified corner rounds when possible to keep shapes consistent.\n- Maintain visual hierarchy with headline, supporting text, and CTA in a clear order.\n\n### Icons & imagery\n\nSystem iconography provides visual clarity, while partner logos and images help users recognize brand context.\n\n![Icons](/images/apps-sdk/icons.png)\n\n**Rules of thumb**\n\n- Use either system icons or custom iconography that fits within ChatGPT's visual world — monochromatic and outlined.\n- Do not include your logo as part of the response. ChatGPT will always append your logo and app name before the widget is rendered.\n- All imagery must follow enforced aspect ratios to avoid distortion.\n\n![Icons & imagery](/images/apps-sdk/iconography.png)\n\n### Accessibility\n\nEvery partner experience should be usable by the widest possible audience.\nAccessibility should be a core consideration when you are building apps for ChatGPT.\n\n**Rules of thumb**\n\n- Text and background must maintain a minimum contrast ratio (WCAG AA).\n- Provide alt text for all images.\n- Support text resizing without breaking layouts.",
    keywords: [
      "system",
      "apps",
      "images",
      "text",
      "chatgpt",
      "icons",
      "sdk",
      "png",
      "colors",
      "consistent",
      "partner",
      "color",
      "rules",
      "visual",
      "brand",
    ],
  },
  {
    id: "ux-principles-0",
    source: "UX Principles",
    heading: "Overview",
    content:
      "Creating a great ChatGPT app is about delivering a focused, conversational experience that feels native to ChatGPT.\n\nThe goal is to design experiences that feel consistent and useful while extending what you can do in ChatGPT conversations in ways that add real value.\n\nGood examples include booking a ride, ordering food, checking availability, or tracking a delivery. These are tasks that are conversational, time bound, and easy to summarize visually with a clear call to action. Poor examples include replicating long form content from a website, requiring complex multi step workflows, or using the space for ads or irrelevant messaging.\n\nUse the UX principles below to guide your development.",
    keywords: [
      "chatgpt",
      "conversational",
      "examples",
      "include",
      "creating",
      "great",
      "app",
      "delivering",
      "focused",
      "experience",
      "feels",
      "native",
      "goal",
      "design",
      "experiences",
    ],
  },
  {
    id: "ux-principles-1",
    source: "UX Principles",
    heading: "Principles for great app UX",
    content:
      'An app should do at least one thing _better_ because it lives in ChatGPT:\n\n- **Conversational leverage** – natural language, thread context, and multi-turn guidance unlock workflows that traditional UI cannot.\n- **Native fit** – the app feels embedded in ChatGPT, with seamless hand-offs between the model and your tools.\n- **Composability** – actions are small, reusable building blocks that the model can mix with other apps to complete richer tasks.\n\nIf you cannot describe the clear benefit of running inside ChatGPT, keep iterating before publishing your app.\n\nOn the other hand, your app should also _improve the user experience_ in ChatGPT by either providing something new to know, new to do, or a better way to show information.\n\nBelow are a few principles you should follow to help ensure your app is a great fit for ChatGPT.\n\n### 1. Extract, don’t port\n\nFocus on the core jobs users use your product for. Instead of mirroring your full website or native app, identify a few atomic actions that can be extracted as tools. Each tool should expose the minimum inputs and outputs needed for the model to take the next step confidently.\n\n### 2. Design for conversational entry\n\nExpect users to arrive mid-conversation, with a specific task in mind, or with fuzzy intent.\nYour app should support:\n\n- Open-ended prompts (e.g. "Help me plan a team offsite").\n- Direct commands (e.g. "Book the conference room Thursday at 3pm").\n- First-run onboarding (teach new users how to engage through ChatGPT).\n\n### 3. Design for the ChatGPT environment\n\nChatGPT provides the conversational surface. Use your UI selectively to clarify actions, capture inputs, or present structured results. Skip ornamental components that do not advance the current task, and lean on the conversation for relevant history, confirmation, and follow-up.\n\n### 4. Optimize for conversation, not navigation\n\nThe model handles state management and routing. Your app supplies:\n\n- Clear, declarative actions with well-typed parameters.\n- Concise responses that keep the chat moving (tables, lists, or short paragraphs instead of dashboards).\n- Helpful follow-up suggestions so the model can keep the user in flow.\n\n### 5. Embrace the ecosystem moment\n\nHighlight what is unique about your app inside ChatGPT:\n\n- Accept rich natural language instead of form fields.\n- Personalize with relevant context gleaned from the conversation.\n- (Optional) Compose with other apps when it saves the user time or cognitive load.',
    keywords: [
      "app",
      "chatgpt",
      "model",
      "actions",
      "conversation",
      "conversational",
      "other",
      "keep",
      "user",
      "new",
      "follow",
      "users",
      "instead",
      "natural",
      "language",
    ],
  },
  {
    id: "ux-principles-2",
    source: "UX Principles",
    heading: "Checklist before publishing",
    content:
      "Answer these yes/no questions before publishing your app. A “no” signals an opportunity to improve your app and have a chance at broader distribution once we open up app submissions later this year.\n\nHowever, please note that we will evaluate each app on a case-by-case basis, and that answering \"yes\" to all of these questions does not guarantee that your app will be selected for distribution: it's only a baseline to help your app be a great fit for ChatGPT.\n\nTo learn about strict requirements for publishing your app, see the [App\nDeveloper Guidelines](/apps-sdk/app-developer-guidelines).\n\n- **Conversational value** – Does at least one primary capability rely on ChatGPT’s strengths (natural language, conversation context, multi-turn dialog)?\n- **Beyond base ChatGPT** – Does the app provide new knowledge, actions, or presentation that users cannot achieve without it (e.g., proprietary data, specialized UI, or a guided flow)?\n- **Atomic, model-friendly actions** – Are tools indivisible, self-contained, and defined with explicit inputs and outputs so the model can invoke them without clarifying questions?\n- **Helpful UI only** – Would replacing every custom widget with plain text meaningfully degrade the user experience?\n- **End-to-end in-chat completion** – Can users finish at least one meaningful task without leaving ChatGPT or juggling external tabs?\n- **Performance & responsiveness** – Does the app respond quickly enough to maintain the rhythm of a chat?\n- **Discoverability** – Is it easy to imagine prompts where the model would select this app confidently?\n- **Platform fit** – Does the app take advantage of core platform behaviors (rich prompts, prior context, multi-tool composition, multimodality, or memory)?\n\nAdditionally, ensure that you avoid:\n\n- Displaying **long-form or static content** better suited for a website or app.\n- Requiring **complex multi-step workflows** that exceed the inline or fullscreen display modes.\n- Using the space for **ads, upsells, or irrelevant messaging**.\n- Surfacing **sensitive or private information** directly in a card where others might see it.\n- **Duplicating ChatGPT’s system functions** (for example, recreating the input composer).\n\n### Next steps\n\nOnce you have made sure your app has great UX, you can polish your app's UI by following our recommendations in the [UI guidelines](/apps-sdk/concepts/ui-guidelines).",
    keywords: [
      "app",
      "chatgpt",
      "guidelines",
      "questions",
      "multi",
      "without",
      "model",
      "yes",
      "publishing",
      "distribution",
      "once",
      "case",
      "only",
      "great",
      "fit",
    ],
  },
  {
    id: "app-submission-guidelines-0",
    source: "app submission guidelines",
    heading: "Overview",
    content:
      "The ChatGPT app ecosystem is built on trust. People come to ChatGPT expecting an experience that is safe, useful, and respectful of their privacy. Developers come to ChatGPT expecting a fair and transparent process. These developer guidelines set the policies every builder is expected to review and follow.\n\nBefore getting into specifics, we recommend first familiarizing yourself with two foundational resources:\n\n- [**UX principles for ChatGPT apps**](https://developers.openai.com/apps-sdk/concepts/ux-principles) - this guide outlines principles and best practices for building ChatGPT apps, as well as a checklist to help you ensure your app is a great fit for ChatGPT.\n- [**UI guidelines for ChatGPT apps**](https://developers.openai.com/apps-sdk/concepts/ui-guidelines) - this guide describes the interaction, layout, and design patterns that help apps feel intuitive, trustworthy, and consistent within ChatGPT.\n\nYou should also read our blog post on [what makes a great ChatGPT app](https://developers.openai.com/blog/what-makes-a-great-chatgpt-app/) to get a sense of the overall approach to building with the Apps SDK.\n\nThe guidelines below outline the minimum standard developers must meet for their app to be considered for publication in ChatGPT, and for their app to remain published and available to ChatGPT users. Apps that demonstrate strong real-world utility and high user satisfaction may be eligible for enhanced distribution opportunities—such as directory placement or proactive suggestions.",
    keywords: [
      "chatgpt",
      "apps",
      "app",
      "developers",
      "guidelines",
      "principles",
      "https",
      "openai",
      "com",
      "sdk",
      "great",
      "come",
      "expecting",
      "concepts",
      "guide",
    ],
  },
  {
    id: "app-submission-guidelines-1",
    source: "app submission guidelines",
    heading: "App fundamentals",
    content:
      "### Purpose and originality\n\nApps should serve a clear purpose and reliably do what they promise. In particular, they should provide functionality or workflows that are not natively supported by ChatGPT’s core conversational capabilities, and that meaningfully help satisfy common user intents expressed in conversation.\n\nOnly use intellectual property that you own or have permission to use. Do not engage in misleading or copycat designs, impersonation, spam, or static frames with no meaningful interaction. Apps should not imply that they are made or endorsed by OpenAI.\n\n### Quality and reliability\n\nApps must behave predictably and reliably. Results should be accurate and relevant to user input. Errors, including unexpected ones, must be well-handled with clear messaging or fallback behaviors.\n\nBefore submission, apps must be thoroughly tested to ensure stability, responsiveness, and low latency across a wide range of scenarios. Apps should not crash, hang, or show inconsistent behavior. Apps should be complete and any app submitted as a trial or demo will not be accepted.\n\n### App name, description, and screenshots\n\nApp names and descriptions should be clear, accurate, and easy to understand. Screenshots must accurately represent app functionality and conform to the required dimensions.\n\n### Tools\n\nMCP tools act as the manual for ChatGPT to use your app. Clear, accurate tool definitions make your app safer, easier for the model to understand, and easier for users to trust.\n\n#### Clear and accurate tool names\n\nTool names should be human-readable, specific, and descriptive of what the tool actually does.\n\n- Tool names must be unique within your app.\n- Use plain language that directly reflects the action, ideally as a verb (e.g.,`get_order_status`).\n- Avoid misleading, overly promotional, or comparative language (e.g., `pick_me`, `best`, `official`).\n\n#### Descriptions that match behavior\n\nEach tool must include a description that explains its purpose clearly and accurately.\n\n- The description should describe what the tool does.\n- Descriptions must not favor or disparage other apps or services or attempt to influence the model to select it over another app’s tools.\n- Descriptions must not recommend overly-broad triggering beyond the explicit user intent and purpose the app fulfills.\n- If a tool’s behavior is unclear or incomplete from its description, your app may be rejected.\n\n#### Correct annotation\n\n[Tool annotations](/apps-sdk/reference#annotations) must be correctly set so that ChatGPT and users understand whether an action is safe or requires extra caution.\n\n- You should label a tool with the `readOnlyHint` annotation if it only retrieves or lists data, but does not change anything outside of ChatGPT.\n- Write or destructive tools (e.g., creating, updating, deleting, posting, sending) must be clearly marked using the `readOnlyHint` and `openWorldHint`.\n- Tools that interact with external systems, accounts, public platforms, or create publicly-visible content must be explicitly labeled using the `openWorldHint` annotation.\n- Incorrect or missing action labels are a common cause of rejection. Double-check to ensure that the `readOnlyHint`, `openWorldHint`, and `destructiveHint` annotations are correctly set and provide a detailed justification for each at submission time.\n\n#### Minimal and purpose-driven inputs\n\nTools should request the minimum information necessary to complete their task.\n\n- Input fields must be directly related to the tool’s stated purpose.\n- Do not request the full conversation history, raw chat transcripts, or broad contextual fields “just in case.” A tool may request a _brief, task-specific_ user intent field only when it meaningfully improves execution and does not expand data collection beyond what is reasonably necessary to respond to the user’s request and for the purposes described in your privacy policy.\n- If needed, rely on the coarse geo location shared by the system. Do not request precise user location data (e.g. GPS coordinates or addresses).\n\n#### Predictable, auditable behavior\n\nTools should behave exactly as their names, descriptions, and inputs indicate.\n\n- Side effects should never be hidden or implicit.\n- If a tool sends data outside the current environment (e.g., posting content, sending messages), this must be clear from the tool definition.\n- Tools should be safe to retry where possible, or clearly indicate when retries may cause repeated effects.\n\nCarefully designed tools help reduce surprises, protect users, and speed up the review process.\n\n### Authentication and permissions\n\nIf your app requires authentication, the flow must be transparent and explicit. Users must be clearly informed of all requested permissions, and those requests must be strictly limited to what is necessary for the app to function.\n\n#### Test credentials\n\nWhen submitting an authenticated app for review, you must provide a login and password for a fully-featured demo account that includes sample data. Apps requiring any additional steps for login—such as requiring new account sign-up or 2FA through an inaccessible account—will be rejected.",
    keywords: [
      "tool",
      "app",
      "not",
      "apps",
      "tools",
      "purpose",
      "clear",
      "user",
      "names",
      "descriptions",
      "data",
      "request",
      "chatgpt",
      "accurate",
      "behavior",
    ],
  },
  {
    id: "app-submission-guidelines-2",
    source: "app submission guidelines",
    heading: "Commerce and monetization",
    content:
      "Currently, apps may conduct commerce **only for physical goods**. Selling digital products or services—including subscriptions, digital content, tokens, or credits—is not allowed, whether offered directly or indirectly (for example, through freemium upsells).\n\nIn addition, apps may not be used to sell, promote, facilitate, or meaningfully enable the following goods or services:\n\n#### **Prohibited goods**\n\n- **Adult content & sexual services**\n  - Pornography, explicit sexual media, live-cam services, adult subscriptions\n  - Sex toys, sex dolls, BDSM gear, fetish products\n- **Gambling**\n  - Real-money gambling services, casino credits, sportsbook wagers, crypto-casino tokens\n- **Illegal or regulated drugs**\n  - Marijuana/THC products, psilocybin, illegal substances\n  - CBD products exceeding legal THC limits\n- **Drug paraphernalia**\n  - Bongs, dab rigs, drug-use scales, cannabis grow equipment marketed for drugs\n- **Prescription & age-restricted medications**\n  - Prescription-only drugs (e.g., insulin, antibiotics, Ozempic, opioids)\n  - Age-restricted Rx products (e.g., testosterone, HGH, fertility hormones)\n- **Illicit goods**\n  - Counterfeit or replica products\n  - Stolen goods or items without clear provenance\n  - Financial-fraud tools (skimmers, fake POS devices)\n  - Piracy tools or cracked software\n  - Wildlife or environmental contraband (ivory, endangered species products)\n- **Malware, spyware & surveillance**\n  - Malware, ransomware, keyloggers, stalkerware\n  - Covert surveillance devices (spy cameras, IMSI catchers, hidden trackers)\n- **Tobacco & nicotine**\n  - Tobacco products\n  - Nicotine products (vapes, e-liquids, nicotine pouches)\n- **Weapons & harmful materials**\n  - Firearms, ammunition, firearm parts\n  - Explosives, fireworks, bomb-making materials\n  - Illegal or age-restricted weapons (switchblades, brass knuckles, crossbows where banned)\n  - Self-defense weapons (pepper spray, stun guns, tasers)\n  - Extremist merchandise or propaganda\n\n#### **Prohibited fraudulent, deceptive, or high-risk services**\n\n- Fake IDs, forged documents, or document falsification services\n- Debt relief, credit repair, or credit-score manipulation schemes\n- Unregulated, deceptive, or abusive financial services\n- Lending, advance-fee, or credit-building schemes designed to exploit users\n- Crypto or NFT offerings involving speculation, consumer deception, or financial abuse\n- Execution of money transfers, crypto transfers, or investment trades\n- Government-service abuse, impersonation, or benefit manipulation\n- Identity theft, impersonation, or identity-monitoring services that enable misuse\n- Certain legal or quasi-legal services that facilitate fraud, evasion, or misrepresentation\n- Negative-option billing, telemarketing, or consent-bypass schemes\n- High-chargeback, fraud-prone, or abusive travel services\n\n### Checkout\n\nApps should use external checkout, directing users to complete purchases on your own domain.\n\n[Instant Checkout](/commerce/guides/get-started#instant-checkout), which is currently in beta, is currently available only to select marketplace partners and may expand to additional marketplaces and retailers over time.\n\nUntil then, standard external checkout is the required approach. No other third-party checkout solutions may be embedded or hosted within the app experience. To learn more, see our [docs on Agentic Commerce](/commerce/).\n\n### Advertising\n\nApps must not serve advertisements and must not exist primarily as an advertising vehicle. Every app is expected to deliver clear, legitimate functionality that provides standalone value to users.",
    keywords: [
      "services",
      "products",
      "checkout",
      "goods",
      "apps",
      "commerce",
      "not",
      "currently",
      "only",
      "crypto",
      "illegal",
      "drugs",
      "legal",
      "age",
      "restricted",
    ],
  },
  {
    id: "app-submission-guidelines-3",
    source: "app submission guidelines",
    heading: "Safety",
    content:
      "### Usage policies\n\nDo not engage in or facilitate activities prohibited under [OpenAI usage policies](https://openai.com/policies/usage-policies/). Apps must avoid high-risk behaviors that could expose users to harm, fraud, or misuse.\n\nStay current with evolving policy requirements and ensure ongoing compliance. Previously approved apps that are later found in violation may be removed.\n\n### Appropriateness\n\nApps must be suitable for general audiences, including users aged 13–17. Apps may not explicitly target children under 13. Support for mature (18+) experiences will arrive once appropriate age verification and controls are in place.\n\n### Respect user intent\n\nProvide experiences that directly address the user’s request. Do not insert unrelated content, attempt to redirect the interaction, or collect data beyond what is reasonably necessary to fulfill the user’s request and what is consistent with your privacy policy.\n\n### Fair play\n\nApps must not include descriptions, titles, tool annotations, or other model-readable fields—at either the tool or app level—that manipulates how the model selects or uses other apps or their tools (e.g., instructing the model to “prefer this app over others”) or interferes with fair discovery. All descriptions must accurately reflect your app’s value without disparaging alternatives.\n\n### Third-party content and integrations\n\n- **Authorized access:** Do not scrape external websites, relay queries, or integrate with third-party APIs without proper authorization and compliance with that party’s terms of service.\n- **Circumvention:** Do not bypass API restrictions, rate limits, or access controls imposed by the third party.\n\n### Iframes and embedded pages\n\nApps can opt in to iframe usage by setting frame_domains on their widget CSP, but highly encourage you to build your app without this pattern. If you choose to use frame_domains, be aware that:\n\n- It is only intended for cases where embedding a third-party experience is essential (e.g., a notebook, IDE, or similar environment).\n- Those apps receive extra manual review and are often not approved for broad distribution.\n- During development, any developer can test frame_domains in developer mode, but approval for public listing is limited to trusted scenarios.",
    keywords: [
      "apps",
      "not",
      "party",
      "usage",
      "policies",
      "app",
      "third",
      "user",
      "model",
      "without",
      "frame_domains",
      "under",
      "openai",
      "users",
      "policy",
    ],
  },
  {
    id: "app-submission-guidelines-4",
    source: "app submission guidelines",
    heading: "Privacy",
    content:
      "### Privacy policy\n\nSubmissions must include a clear, published privacy policy explaining - at minimum - the categories of personal data collected, the purposes of use, the categories of recipients, and any controls offered to your users. Follow this policy at all times. Users can review your privacy policy before installing your app.\n\n### Data collection\n\n- **Collection minimization:** Gather only the minimum data required to perform the tool’s function. Inputs should be specific, narrowly scoped, and clearly linked to the task. Avoid “just in case” fields or broad profile data. Design the input schema to limit data collection by default, rather than a funnel for optional context.\n- **Response minimization:** Tool responses must return only data that is directly relevant to the user’s request and the tool’s stated purpose. Do not include diagnostic, telemetry, or internal identifiers—such as session IDs, trace IDs, request IDs, timestamps, or logging metadata—unless they are strictly required to fulfill the user’s query.\n- **Restricted data:** Do not collect, solicit, or process the following categories of Restricted Data:\n  - Information subject to Payment Card Information Data Security Standards (PCI DSS)\n  - Protected health information (PHI)\n  - Government identifiers (such as social security numbers)\n  - Access credentials and authentication secrets (such as API keys, MFA/OTP codes, or passwords).\n- **Regulated Sensitive Data:** Do not collect personal data considered “sensitive” or “special category” in the jurisdiction in which the data is collected unless collection is strictly necessary to perform the tool’s stated function; the user has provided legally adequate consent; and the collection and use is clearly and prominently disclosed at or before the point of collection.\n- **Data boundaries:**\n  - Avoid requesting raw location fields (e.g., city or coordinates) in your input schema. When location is needed, obtain it through the client’s controlled side channel (such as environment metadata or a referenced resource) so appropriate policy and consent controls can be applied. This reduces accidental PII capture, enforces least-privilege access, and keeps location handling auditable and revocable.\n  - Your app must not pull, reconstruct, or infer the full chat log from the client or elsewhere. Operate only on the explicit snippets and resources the client or model chooses to send. This separation can help prevent covert data expansion and keep analysis limited to intentionally shared content.\n\n### Transparency and user control\n\n- **Data practices:** Do not engage in surveillance, tracking, or behavioral profiling—including metadata collection such as timestamps, IPs, or query patterns—unless explicitly disclosed, narrowly scoped, subject to meaningful user control, and aligned with [OpenAI’s usage policies](https://openai.com/policies/usage-policies/).\n- **Accurate action labels:** Mark any tool that changes external state (create, modify, delete) as a write action. You should only mark a tool as a read-only action if it is side-effect-free and safe to retry. Destructive actions require clear labels and friction (e.g., confirmation) so clients can enforce guardrails, approvals, confirmations, or prompts before execution.\n- **Preventing data exfiltration:** Any action that sends data outside the current boundary (e.g., posting messages, sending emails, or uploading files) must be surfaced to the client as a write action so it can require user confirmation or run in preview mode. This reduces unintentional data leakage and aligns server behavior with client-side security expectations.",
    keywords: [
      "data",
      "collection",
      "tool",
      "user",
      "policy",
      "only",
      "not",
      "such",
      "client",
      "action",
      "privacy",
      "categories",
      "any",
      "before",
      "ids",
    ],
  },
  {
    id: "app-submission-guidelines-5",
    source: "app submission guidelines",
    heading: "Developer verification",
    content:
      "### Verification\n\nAll submissions must come from verified individuals or organizations. Inside the [OpenAI Platform Dashboard general settings](https://platform.openai.com/settings/organization/general), we provide a way to confirm your identity and affiliation with any business you wish to publish on behalf of. Misrepresentation, hidden behavior, or attempts to game the system may result in removal from the program.\n\n### Support contact details\n\nYou must provide customer support contact details where end users can reach you for help. Keep this information accurate and up to date.",
    keywords: [
      "openai",
      "platform",
      "general",
      "settings",
      "provide",
      "support",
      "contact",
      "details",
      "verification",
      "all",
      "submissions",
      "come",
      "verified",
      "individuals",
      "organizations",
    ],
  },
  {
    id: "app-submission-guidelines-6",
    source: "app submission guidelines",
    heading: "Submitting your app",
    content:
      "Users with the Owner role may submit an app for review from the [OpenAI Platform Dashboard](http://platform.openai.com/apps-manage).\n\nWhile you can publish multiple, unique apps within a single Platform organization, each may only have one version in review at a time. You can review the status of the review within the Dashboard and will receive an email notification informing you of any status changes.\n\nTo learn more about the app submission process, refer to our [dedicated guide](/apps-sdk/deploy/submission).",
    keywords: [
      "review",
      "platform",
      "apps",
      "app",
      "openai",
      "dashboard",
      "within",
      "status",
      "submission",
      "users",
      "owner",
      "role",
      "submit",
      "http",
      "com",
    ],
  },
  {
    id: "monetization-0",
    source: "monetization",
    heading: "Overview",
    content:
      "When building a ChatGPT app, developers are responsible for choosing how to monetize their experience. Today, the **recommended** and **generally available** approach is to use **external checkout**, where users complete purchases on the developer’s own domain. While current approval is limited to apps for physical goods purchases, we are actively working to support a wider range of commerce use cases.\n\nWe’re also enabling **Instant Checkout** in ChatGPT apps for select marketplace partners (beta), with plans to extend access to more marketplaces and physical-goods retailers over time. Until then, we recommend routing purchase flows to your standard external checkout.",
    keywords: [
      "checkout",
      "chatgpt",
      "external",
      "purchases",
      "apps",
      "physical",
      "goods",
      "building",
      "app",
      "developers",
      "responsible",
      "choosing",
      "monetize",
      "experience",
      "today",
    ],
  },
  {
    id: "monetization-1",
    source: "monetization",
    heading: "Recommended Monetization Approach",
    content:
      "### ✅ External Checkout (recommended)\n\n**External checkout** means directing users from ChatGPT to a **merchant-hosted checkout flow** on your own website or application, where you handle pricing, payments, subscriptions, and fulfillment.\n\nThis is the recommended approach for most developers building ChatGPT apps.\n\n#### How it works\n\n1. A user interacts with your app in ChatGPT.\n2. Your app presents purchasable items, plans, or services (e.g., “Upgrade,” “Buy now,” “Subscribe”).\n3. When the user decides to purchase, your app links or redirects them out of ChatGPT and to your external checkout flow.\n4. Payment, billing, taxes, refunds, and compliance are handled entirely on your domain.\n5. After purchase, the user can return to ChatGPT with confirmation or unlocked features.\n\n### Instant Checkout in ChatGPT apps (private beta)\n\nInstant Checkout is limited to select marketplaces today and is not available to all users.\n\nThe `requestCheckout` function lets your widget hand a checkout session to ChatGPT and let the host display payment options on your behalf. You prepare a checkout session (line items, totals, provider info), render it in your widget, then call `requestCheckout(session_data)` to open the Instant Checkout UI. When the user clicks buy, a token representing the selected payment method is sent to your MCP server via the `complete_checkout` tool call. You can use your PSP integration to collect payment using this token, and send back finalized order details as a response to the `complete_checkout` tool call.\n\n### Flow at a glance\n\n1. **Server prepares session**: An MCP tool returns checkout session data (session id, line items, totals, payment provider) in `structuredContent`.\n2. **Widget previews cart**: The widget renders line items and totals so the user can confirm.\n3. **Widget calls `requestCheckout`**: The widget invokes `requestCheckout(session_data)`. ChatGPT opens Instant Checkout, displays the amount to charge, and displays various payment methods.\n4. **Server finalizes**: Once the user clicks the pay button, the widget calls back to your MCP via the `complete_checkout` tool call. The MCP tool returns the completed order, which will be returned back to widget as a response to `requestCheckout`.",
    keywords: [
      "checkout",
      "chatgpt",
      "widget",
      "user",
      "payment",
      "requestcheckout",
      "session",
      "tool",
      "items",
      "instant",
      "call",
      "mcp",
      "external",
      "flow",
      "app",
    ],
  },
  {
    id: "monetization-2",
    source: "monetization",
    heading: "Checkout session",
    content:
      "You are responsible for constructing the checkout session payload that the host will render. The exact values for certain fields such as `id` and `payment_provider` depend on your PSP (payment service provider) and commerce backend. In practice, your MCP tool should return:\n\n- Line items and quantities the user is purchasing.\n- Totals (subtotal, tax, discounts, fees, total) that match your backend calculations.\n- Provider metadata required by your PSP integration.\n- Legal and policy links (terms, refund policy, etc.).\n\nThe checkout session payload follows the spec defined in the [ACP](https://developers.openai.com/commerce/specs/checkout#response).",
    keywords: [
      "checkout",
      "session",
      "payload",
      "psp",
      "provider",
      "commerce",
      "backend",
      "policy",
      "responsible",
      "constructing",
      "host",
      "render",
      "exact",
      "values",
      "certain",
    ],
  },
  {
    id: "monetization-3",
    source: "monetization",
    heading: "Widget: calling `requestCheckout`",
    content:
      'The host provides `window.openai.requestCheckout`. Use it to open the Instant Checkout UI when the user initiates a purchase:\n\nExample:\n\n```tsx\nasync function handleCheckout(sessionJson: string) {\n  const session = JSON.parse(sessionJson);\n\n  if (!window.openai?.requestCheckout) {\n    throw new Error("requestCheckout is not available in this host");\n  }\n\n  // Host opens the Instant Checkout UI.\n  const order = await window.openai.requestCheckout({\n    ...session,\n    id: checkout_session_id, // Every unique checkout session should have a unique id\n  });\n\n  return order; // host returns the order payload\n}\n```\n\nIn your component, you might initiate this in a button click:\n\n```tsx\n\n\n{\n    setIsLoading(true);\n    try {\n      const orderResponse = await handleCheckout(checkoutSessionJson);\n      setOrder(orderResponse);\n    } catch (error) {\n      console.error(error);\n    } finally {\n      setIsLoading(false);\n    }\n  }}\n>\n  {isLoading ? "Loading..." : "Checkout"}\n\n\n```\n\nHere is a minimal example that shows the shape of a checkout request you pass to the host. Populate the `merchant_id` field with the value specified by your PSP:\n\n```tsx\nconst checkoutRequest = {\n  id: checkoutSessionId,\n  payment_provider: {\n    provider: "<PSP_NAME>",\n    merchant_id: "<MERCHANT_ID>",\n    supported_payment_methods: ["card", "apple_pay", "google_pay"],\n  },\n  status: "ready_for_payment",\n  currency: "USD",\n  totals: [\n    {\n      type: "total",\n      display_text: "Total",\n      amount: 330,\n    },\n  ],\n  links: [\n    { type: "terms_of_use", url: "<TERMS_OF_USE_URL>" },\n    { type: "privacy_policy", url: "<PRIVACY_POLICY_URL>" },\n  ],\n  payment_mode: "live",\n};\n\nconst response = await window.openai.requestCheckout(checkoutRequest);\n```\n\nKey points:\n\n- `window.openai.requestCheckout(session)` opens the host checkout UI.\n- The promise resolves with the order result or rejects on error/cancel.\n- Render the session JSON so users can review what they’re paying for.\n- Refer to the [ACP](https://developers.openai.com/commerce/specs/checkout#paymentprovider) for possible `provider` values.\n- Consult your PSP to get your PSP specific `merchant_id` value.',
    keywords: [
      "checkout",
      "host",
      "openai",
      "requestcheckout",
      "window",
      "const",
      "session",
      "error",
      "order",
      "merchant_id",
      "tsx",
      "await",
      "psp",
      "type",
      "instant",
    ],
  },
  {
    id: "monetization-4",
    source: "monetization",
    heading: "MCP server: expose the `complete_checkout` tool",
    content:
      'You can mirror this pattern and swap in your logic:\n\n```py\n@tool(description="")\nasync def complete_checkout(\n    self,\n    checkout_session_id: str,\n    buyer: Buyer,\n    payment_data: PaymentData,\n) -> types.CallToolResult:\n    return types.CallToolResult(\n        content=[],\n        structuredContent={\n            "id": checkout_session_id,\n            "status": "completed",\n            "currency": "USD",\n            "order": {\n                "id": "order_id_123",\n                "checkout_session_id": checkout_session_id,\n                "permalink_url": "",\n            },\n        },\n        _meta={META_SESSION_ID: "checkout-flow"},\n        isError=False,\n    )\n```\n\nRefer to the ACP specs for [buyer](https://developers.openai.com/commerce/specs/checkout#buyer) and [payment_data](https://developers.openai.com/commerce/specs/checkout#paymentdata) objects.\n\nAdapt this to:\n\n- Integrate with your PSP to charge the payment method within `payment_data`.\n- Persist the order in your backend.\n- Return authoritative order/receipt data. The response should follow the spec defined in [ACP](https://developers.openai.com/commerce/specs/checkout#response-2).\n- Include `_meta.openai/outputTemplate` if you want to render a confirmation widget.\n\nRefer to the following PSP specific monetization guides for information on how to collect payments:\n\n- [Stripe](https://docs.stripe.com/agentic-commerce/apps)\n- [Adyen](https://docs.adyen.com/online-payments/agentic-commerce)',
    keywords: [
      "https",
      "com",
      "commerce",
      "checkout_session_id",
      "buyer",
      "checkout",
      "specs",
      "openai",
      "payment_data",
      "order",
      "developers",
      "paymentdata",
      "types",
      "calltoolresult",
      "return",
    ],
  },
  {
    id: "monetization-5",
    source: "monetization",
    heading: "Error Handling",
    content:
      "The `complete_checkout` tool call can send back [messages](https://developers.openai.com/commerce/specs/checkout#message-type--error) of type `error`. Error messages with `code` set to `payment_declined` or `requires_3ds` will be displayed on the Instant Checkout UI. All other error messages will be sent back to the widget as a response to `requestCheckout`. The widget can display the error as desired.",
    keywords: [
      "error",
      "messages",
      "back",
      "checkout",
      "type",
      "widget",
      "complete_checkout",
      "tool",
      "call",
      "send",
      "https",
      "developers",
      "openai",
      "com",
      "commerce",
    ],
  },
  {
    id: "monetization-6",
    source: "monetization",
    heading: "Test payment mode",
    content:
      "You can set the value of the `payment_mode` field to `test` in the call to `requestCheckout`. This will present an Instant Checkout UI that accepts test cards (such as the 4242 test card). The resulting `token` within `payment_data` that is passed to the `complete_checkout` tool can be processed in the staging environment of your PSP. This allows you to test end-to-end flows without moving real funds.\n\nNote that in test payment mode, you might have to set a different value for `merchant_id`. Refer to your PSP's monetization guide for more details.",
    keywords: [
      "test",
      "set",
      "value",
      "psp",
      "end",
      "payment_mode",
      "field",
      "call",
      "requestcheckout",
      "present",
      "instant",
      "checkout",
      "accepts",
      "cards",
      "such",
    ],
  },
  {
    id: "monetization-7",
    source: "monetization",
    heading: "Implementation checklist",
    content:
      "1. **Define your checkout session model**: include ids, payment_provider, line_items, totals, and legal links as per the [ACP](https://developers.openai.com/commerce/specs/checkout#paymentprovider).\n2. **Return the session from your MCP tool** in `structuredContent` alongside your widget template.\n3. **Render the session in the widget** so users can review items, totals, and terms.\n4. **Call `requestCheckout(session_data)`** on user action; handle the resolved order or error.\n5. **Charge the user** by implementing the `complete_checkout` MCP tool which returns an ACP spec [response](https://developers.openai.com/commerce/specs/checkout#response-2).\n6. **Test end-to-end** with realistic amounts, taxes, and discounts to ensure the host renders the totals you expect.",
    keywords: [
      "checkout",
      "session",
      "totals",
      "acp",
      "https",
      "developers",
      "openai",
      "com",
      "commerce",
      "specs",
      "mcp",
      "tool",
      "widget",
      "user",
      "response",
    ],
  },
];

export const SDK_DOCS_SOURCES = [
  "API and SDK reference",
  "Authentication",
  "Build your ChatGPT UI",
  "Build your MCP server",
  "Connect from ChatGPT",
  "Define tools",
  "Deploy your app",
  "Design components",
  "MCP",
  "Managing State",
  "Optimize Metadata",
  "Quickstart",
  "Reference",
  "Security and Privacy",
  "Submit your app",
  "Test your integration",
  "Troubleshooting",
  "UI Guidelines",
  "UX Principles",
  "app submission guidelines",
  "monetization",
];
